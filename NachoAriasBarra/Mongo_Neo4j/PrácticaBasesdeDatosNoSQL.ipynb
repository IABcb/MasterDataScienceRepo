{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Práctica: Bases de Datos No Convencionales (curso 2016-2017)\n",
    "\n",
    "### Autores\n",
    "* Ignacio Arias Barra\n",
    "* Miguel Ángel Monjas Llorente\n",
    "* Raúl Sánchez Martín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte I: Mongo DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1) Captura y procesamiento de datos\n",
    "#### Esquema de base de datos\n",
    "La base de datos DBLP Computer Science Bibliography está disponible mediante un fichero XML, en el cual se definen ocho tipos de elementos. Los más relevantes son tres: artículos de revista (`article`), artículos en congresos (`inproceedings`) y capítulos de libros (`incollection`). Son estos elementos los que se utilizarán para esta práctica. Para cada uno de dichos elementos se proporcionan: autores, título, páginas, el nombre del libro o revista, la fecha, además de otros atributos. A continuación se proporciona una muestra del fichero XML:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n",
    "<dblp>\n",
    "    <inproceedings mdate=\"2005-11-30\" key=\"conf/ic/HeuerHRM00\">\n",
    "        <author>Andreas Heuer 0002</author>\n",
    "        <author>Ernst Georg Haffner</author>\n",
    "        <author>Uwe Roth</author>\n",
    "        <author>Christoph Meinel</author>\n",
    "        <title>\n",
    "\t\t\tA Hyperlink Focused Browse Assistant for the World Wide Web.\n",
    "\t\t</title>\n",
    "        <pages>79-84</pages>\n",
    "        <year>2000</year>\n",
    "        <crossref>conf/ic/2000</crossref>\n",
    "        <booktitle>International Conference on Internet Computing</booktitle>\n",
    "        <url>db/conf/ic/ic2000.html#HeuerHRM00</url>\n",
    "    </inproceedings>\n",
    "    <incollection>\n",
    "        <title>Finding Community Topics and Membership in Graphs</title>\n",
    "        <author>Revelle, Matt</author>\n",
    "        <author>Domeniconi, Carlotta</author>\n",
    "        <author>Sweeney, Mack</author>\n",
    "        <author>Johri, Aditya</author>\n",
    "        <year>2015</year>\n",
    "        <isbn>978-3-319-23524-0</isbn>\n",
    "        <booktitle>\n",
    "\t\t\tMachine Learning and Knowledge Discovery in Databases\n",
    "\t\t</booktitle>\n",
    "        <volume>9285</volume>\n",
    "        <series>Lecture Notes in Computer Science</series>\n",
    "        <doi>10.1007/978-3-319-23525-7_38</doi>\n",
    "        <url>http://dx.doi.org/10.1007/978-3-319-23525-7_38</url>\n",
    "        <publisher>Springer International Publishing</publisher>\n",
    "        <pages>625-640</pages>\n",
    "    </incollection>\n",
    "    <article mdate=\"2007-10-24\" key=\"journals/jise/Chang07\">\n",
    "        <title>\n",
    "\t\t\tNew Constructions of Distance-Increasing Mappings and \n",
    "            Permutation Arrays.\n",
    "\t\t</title>\n",
    "        <pages>1227-1239</pages>\n",
    "        <year>2007</year>\n",
    "        <volume>23</volume>\n",
    "        <journal>J. Inf. Sci. Eng.</journal>\n",
    "        <number>4</number>\n",
    "        <ee>http://www.iis.sinica.edu.tw/page/jise/2007/200707_17.html</ee>\n",
    "        <url>db/journals/jise/jise23.html#Chang07</url>\n",
    "    </article>\n",
    "    <inproceedings mdate=\"2003-10-09\" key=\"conf/ic/HarousD03\">\n",
    "        <author>Saad Harous</author>\n",
    "        <author>Mahieddine Djoudi</author>\n",
    "        <title>\n",
    "\t\t\tA Cooperative Authoring System for Intelligent Tutoring Systems.\n",
    "\t\t</title>\n",
    "        <pages>723-729</pages>\n",
    "        <year>2003</year>\n",
    "        <crossref>conf/ic/2003-2</crossref>\n",
    "        <booktitle>International Conference on Internet Computing</booktitle>\n",
    "        <url>db/conf/ic/ic2003-2.html#HarousD03</url>\n",
    "    </inproceedings>\n",
    "    <article mdate=\"2012-03-22\" key=\"journals/jise/LuH12\">\n",
    "        <author>Shyue-Kung Lu</author>\n",
    "        <author>Ya-Chen Huang</author>\n",
    "        <title>\n",
    "\t\t\tImproving Reusability of Test Symbols for Test Data Compression.\n",
    "\t\t</title>\n",
    "        <pages>351-364</pages>\n",
    "        <year>2012</year>\n",
    "        <volume>28</volume>\n",
    "        <journal>J. Inf. Sci. Eng.</journal>\n",
    "        <number>2</number>\n",
    "        <ee>http://www.iis.sinica.edu.tw/page/jise/2012/201203_07</ee>\n",
    "        <url>db/journals/jise/jise28.html#LuH12</url>\n",
    "    </article>\n",
    "</dblp>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "De toda la información proporcionada en el fichero XML, para cada ítem nos quedaremos solo con los siguientes atributos (al no ser necesarios más datos, de acuerdo a las consultas que se desea realizar):\n",
    "* título (`title`)\n",
    "* autor (`author`)\n",
    "* identificador del artículo (`id`)\n",
    "* año de publicación (`year`)\n",
    "* tipo de publicación (`type`)\n",
    "* nombre del contenedor en el que halla el artículo, conferencia o capítulo (`container`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Procesado del dataset XML\n",
    "La estrategia de procesado del dataset comienza fragmentando el fichero XML original en ficheros de menor tamaño (pero que siguen siendo ficheros válidos XLM), utilizando un programa en Python, `splitter.py`, adaptado de <https://gist.github.com/benallard/8042835> y <http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python/12309296> (para poder ser ejecutado en Python 2.7 y 3.5). El código de `splitter.py`, así como el del resto de programas y scripts utilizados en esta práctica, se encuentra en un repositorio GitHub (<https://github.com/raul-sanchez-martin/practica_mongo>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A continuación, se parsean los ficheros resultantes para transformarlos en ficheros en formato JSON (de hecho se trata de *JSON Lines text file format*; esto es, el fichero no sigue el formato JSON, sino que es cada línea la que constituye un documento JSON válido). Se utiliza para ello el programa en Python `parser.py` (adaptado de <https://github.com/songmw90/dblp-parser>). Se muestra el código a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from lxml import etree\n",
    "import json\n",
    "import io, os\n",
    "\n",
    "def iterate_tree(context, prefix):\n",
    "    collaborations = [u'inproceedings', u'incollection', u'article']\n",
    "    # xml categories\n",
    "    author_array = []\n",
    "    title = ''\n",
    "\n",
    "    # read chunk line by line\n",
    "    # we focus author and title\n",
    "    counter = 0\n",
    "    for _, elem in context:\n",
    "        record = {}\n",
    "        record[\"author\"] = []\n",
    "        if elem.tag == 'author':\n",
    "            author_array.append(elem.text)\n",
    "\n",
    "        if elem.tag == 'title':\n",
    "            if elem.text:\n",
    "                title = elem.text\n",
    "\n",
    "        if elem.tag == 'journal' or elem.tag == 'booktitle':\n",
    "            if elem.text:\n",
    "                container = elem.text\n",
    "\n",
    "        if elem.tag == 'year':\n",
    "            if elem.text:\n",
    "                year = elem.text\n",
    "\n",
    "        if elem.tag in collaborations:\n",
    "            if len(author_array) is not 0 and title is not '':\n",
    "                # rejected paper has no author or title\n",
    "                # it should be checked\n",
    "                record[\"title\"] = title\n",
    "                record[\"author\"] = [author for author in author_array]\n",
    "                record[\"id\"] = elem.get(\"key\")\n",
    "                record[\"year\"] = int(year)\n",
    "                record[\"type\"] = elem.tag\n",
    "                record_json = json.dumps(record, \n",
    "                                         sort_keys=True, \n",
    "                                         ensure_ascii=False)\n",
    "\n",
    "                file_name = '{0}-{1:02d}.json'.format(prefix, counter)\n",
    "                try:\n",
    "                    stats = os.stat(file_name)\n",
    "                    file_size = stats.st_size\n",
    "                except FileNotFoundError :\n",
    "                    file_size = 0\n",
    "                if file_size > 104857600 :\n",
    "                    counter += 1\n",
    "                    file_name = '{0}{1:02d}.json'.format(prefix, counter)\n",
    "                write_element(record_json, file_name)\n",
    "\n",
    "                title = ''\n",
    "                del author_array[:]\n",
    "\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            try :\n",
    "                del elem.getparent()[0]\n",
    "            except TypeError:\n",
    "                break\n",
    "    del context\n",
    "\n",
    "def write_element (elem, file_output):\n",
    "    print ('.')\n",
    "    with io.open(file_output, 'a', encoding='utf8') as outfile:\n",
    "        outfile.write(to_unicode(elem))\n",
    "        outfile.write(u\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        to_unicode = unicode\n",
    "    except NameError:\n",
    "        to_unicode = str\n",
    "    json_file_prefix = \"dblp\"\n",
    "    input_files = ['dblp.0.xml', 'dblp.1.xml', 'dblp.2.xml']\n",
    "    for input_file in input_files :\n",
    "        context = etree.iterparse(input_file, load_dtd=True, html=True)\n",
    "        # To use iterparse, we don't need to read all of xml.\n",
    "        iterate_tree(context, json_file_prefix)\n",
    "    print ('Finished')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Se muestra a continuación un ejemplo del resultado del proceso de parseado de los datos (cada línea tiene ajuste de línea para claridad de la visualización):\n",
    "```json\n",
    "{\"author\": [\"Paulo B. Ges\", \"Ram D. Gopal\", \"Nai-Kuang Chen\"], \n",
    "  \"container\": \"Decision Support Systems\", \"id\": \"journals/dss/GoesGC97\", \n",
    "  \"title\": \"Query evaluation management design and prototype implementation.\", \n",
    "  \"type\": \"article\", \"year\": 1997}\n",
    "{\"author\": [\"Gleiber Fernandes Royes\", \"Rogrio Cid Bastos\"], \n",
    "  \"container\": \"Decision Support Systems\", \"id\": \"journals/dss/RoyesB06\", \n",
    "  \"title\": \"Uncertainty analysis in political forecasting.\", \n",
    "{\"author\": [\"Symeon Bozapalidis\", \"Zoltn Flp 0001\", \"George Rahonis\"], \n",
    "  \"container\": \"Acta Inf.\", \"id\": \"journals/acta/BozapalidisFR12\", \n",
    "  \"title\": \"Equational weighted tree transformations.\", \n",
    "  \"type\": \"article\", \"year\": 2012}\n",
    "\n",
    "```\n",
    "Se trata de 12 ficheros de un tamaño aproximado de 100 MB cada vez. En total 1,08 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2) Almacenamiento de datos\n",
    "\n",
    "Para realizar la carga de documentos a la base de datos de MongoDB, se ha creado un *script* en *bash*, `load_documents.sh`. Dicho *script* detecta todos los arhivos JSON almacenados en la carpeta en la que se ejecuta y los carga en MongoDB utilizando `mongoimport`. El código está preparado para cargar diversos archivos JSON en una misma coleción de documentos. Esta especialmente preparado para los archivos provenientes del paso anterior: \n",
    "```shell\n",
    "#!/bin/bash\n",
    "\n",
    "# Bash script to load all the JSON files of a folder into a MongoDB \n",
    "# collection. In order to use this script, set the wd of a terminal \n",
    "# in the folder where the JSON files are located, and type in the \n",
    "# terminal:\n",
    "# ./load_documents.sh <dababase_name> <collection_name>\n",
    "# Don't forget to set the load_documents.sh file as an executable\n",
    "\n",
    "if [ \"$#\" -ne 2 ]; then\n",
    "  echo \"Invalid number of arguments. \\\n",
    "Please, enter <dababase_name> and <collection_name>\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "mongo $1 --eval \"db.dropDatabase()\"\n",
    "\n",
    "ls -1 *.json | sed 's/.json$//' | while read col; do \n",
    "    mongoimport --db $1 --collection $2 --file $col.json; \n",
    "done\n",
    "\n",
    "```\n",
    "Para su ejecución, en primer lugar hay que copiar el *script* en el directorio donde se encuentran los ficheros JSON cuyo contenido hay que cargar y darle los permisos correspondientes. A continuación, se ejecuta el script `load_documents.sh` mediante el siguiente comando:\n",
    "```\n",
    "./load_documents.sh <nombre_base_datos> <nombre_colección>\n",
    "```\n",
    "\n",
    "donde `<nombre_base_datos>` y `<nombre_colección>` corresponden respectivamente al nombre de la base de datos (`documentos`) y de la colección (`publicaciones`) en la que queremos guardar los documentos.\n",
    "\n",
    "Los documentos JSON que se han introducido en la base de datos MongoDB se encuentran también en el *bucket* de S3 [urjc.datascience.bdnc/dbpl_convertidos](https://console.aws.amazon.com/s3/buckets/urjc.datascience.bdnc/dbpl_convertidos/?region=eu-west-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3) Análisis de datos\n",
    "\n",
    "Las consultas se efectuarán utilizando el módulo de Python `pymongo`. Una vez cargados todos los documentos en la base de datos en el apartado anterior, el primer paso va a ser establecer la conexión a dicha base de datos desde `pymongo` y comprobar que todo funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N\\xc3\\xbamero de documentos: ', 5507168)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.son import SON\n",
    "from pymongo import IndexModel, ASCENDING, DESCENDING\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "#conexion a la Base de Datos\n",
    "conex = pymongo.MongoClient('localhost', 27017)\n",
    "db = conex.documentos\n",
    "publicaciones = db.publicaciones\n",
    "print(\"Número de documentos: \", publicaciones.find().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Una vez que se ha comprobado que existe una conexión satisfactoria con la base de datos, se ha dado respuesta a cada una de las preguntas incluidas en el enunciado de la práctica.\n",
    "\n",
    "Antes de efectuar las consultas, se procede a la creación de los índices necesarios para optimizar las consultas. Se han obtenido del análisis del enunciado y son los siguientes:\n",
    "* `author`\n",
    "* `type`\n",
    "* `year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'author_1', u'year_1', u'type_1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Índices\n",
    "# Author\n",
    "index_author = IndexModel([(\"author\", ASCENDING)])\n",
    "# Year\n",
    "index_year = IndexModel([(\"year\", ASCENDING)])\n",
    "# Type\n",
    "index_type = IndexModel([(\"type\", ASCENDING)])\n",
    "\n",
    "publicaciones.create_indexes([index_author, index_year, index_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**1. Listado de todas las publicaciones de un autor determinado**.\n",
    "\n",
    "En el siguiente bloque de código se incluyen las sentencias necesarias para realizar la consulta necesaria para responder a la pregunta. Para poder efectuarla, el nombre del autor se pasa con la variable `author_to_search`. En el ejemplo usamos al autor `Joost Engelfriet`.\n",
    "\n",
    "*Para esta pregunta, el índice utilizado es `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publicaciones del autor JOOST ENGELFRIET :\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Context-Free Graph Languages of Bounded Degree are Generated by Apex Graph Grammars.', u'author': [u'Joost Engelfriet', u'Linda Heyker', u'George Leih'], u'year': 1994, u'_id': ObjectId('5908971142e9c49335e1e2c4'), u'type': u'article', u'id': u'journals/acta/EngelfrietHL94'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'High Level Tree Transducers and Iterated Pushdown Tree Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1988, u'_id': ObjectId('5908971142e9c49335e1e2e3'), u'type': u'article', u'id': u'journals/acta/EngelfrietV88'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Extended multi bottom-up tree transducers.', u'author': [u'Joost Engelfriet', u'Eric Lilin', u'Andreas Maletti'], u'year': 2009, u'_id': ObjectId('5908971142e9c49335e1e2f0'), u'type': u'article', u'id': u'journals/acta/EngelfrietLM09'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Context-Free Graph Grammars and Concatenation of Graphs.', u'author': [u'Joost Engelfriet', u'Jan Joris Vereijken'], u'year': 1997, u'_id': ObjectId('5908971142e9c49335e1e302'), u'type': u'article', u'id': u'journals/acta/EngelfrietV97'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'A new natural structural congruence in the pi-calculus with replication.', u'author': [u'Joost Engelfriet', u'Tjalling Gelsema'], u'year': 2004, u'_id': ObjectId('5908971142e9c49335e1e334'), u'type': u'article', u'id': u'journals/acta/EngelfrietG04'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Axioms for Generalized Graphs, Illustrated by a Cantor-Bernstein Proposition.', u'author': [u'Joost Engelfriet', u'Tjalling Gelsema'], u'year': 1998, u'_id': ObjectId('5908971142e9c49335e1e340'), u'type': u'article', u'id': u'journals/acta/EngelfrietG98'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Apex Graph Grammars and Attribute Grammars.', u'author': [u'Joost Engelfriet', u'George Leih', u'Grzegorz Rozenberg'], u'year': 1988, u'_id': ObjectId('5908971142e9c49335e1e406'), u'type': u'article', u'id': u'journals/acta/EngelfrietLR88'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'The time complexity of typechecking tree-walking tree transducers.', u'author': [u'Mirko Krivnek', u'Jaroslav Morvek', u'Joost Engelfriet'], u'year': 2009, u'_id': ObjectId('5908971142e9c49335e1e4c5'), u'type': u'article', u'id': u'journals/acta/Engelfriet09'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Branching Processes of Petri Nets.', u'author': [u'Joost Engelfriet'], u'year': 1991, u'_id': ObjectId('5908971142e9c49335e1e4fb'), u'type': u'article', u'id': u'journals/acta/Engelfriet91'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Extended Linear Macro Grammars, Iteration Grammars, and Register Programs.', u'author': [u'Peter R. J. Asveld', u'Joost Engelfriet'], u'year': 1979, u'_id': ObjectId('5908971142e9c49335e1e54c'), u'type': u'article', u'id': u'journals/acta/AsveldE79'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'The Formal Power of One-Visit Attribute Grammars.', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1981, u'_id': ObjectId('5908971142e9c49335e1e567'), u'type': u'article', u'id': u'journals/acta/EngelfrietF81'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Context-Free Hypergraph Grammars have the Same Term-Generating Power as Attribute Grammars.', u'author': [u'Joost Engelfriet', u'Linda Heyker'], u'year': 1992, u'_id': ObjectId('5908971142e9c49335e1e573'), u'type': u'article', u'id': u'journals/acta/EngelfrietH92'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Two-way pebble transducers for partial functions and their composition.', u'author': [u'Joost Engelfriet'], u'year': 2015, u'_id': ObjectId('5908971142e9c49335e1e597'), u'type': u'article', u'id': u'journals/acta/Engelfriet15'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'A comparison of pebble tree transducers with macro tree transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2003, u'_id': ObjectId('5908971142e9c49335e1e735'), u'type': u'article', u'id': u'journals/acta/EngelfrietM03'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Attribute Storage Optimization by Stacks.', u'author': [u'Joost Engelfriet', u'Willem de Jong'], u'year': 1990, u'_id': ObjectId('5908971142e9c49335e1e771'), u'type': u'article', u'id': u'journals/acta/EngelfrietJ89'}\n",
      "\n",
      "  {u'container': u'Acta Inf.', u'title': u'Iterated Deterministic Substitution.', u'author': [u'Peter R. J. Asveld', u'Joost Engelfriet'], u'year': 1977, u'_id': ObjectId('5908971142e9c49335e1e833'), u'type': u'article', u'id': u'journals/acta/AsveldE77'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'The equivalence problem for deterministic MSO tree transducers is decidable.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2006, u'_id': ObjectId('5908971e42e9c49335e83ace'), u'type': u'article', u'id': u'journals/ipl/EngelfrietM06'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'An Elementary Proof of Double Greibach Normal Form.', u'author': [u'Joost Engelfriet'], u'year': 1992, u'_id': ObjectId('5908971e42e9c49335e83c61'), u'type': u'article', u'id': u'journals/ipl/Engelfriet92'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'A Kleene characterization of computability.', u'author': [u'Joost Engelfriet'], u'year': 2007, u'_id': ObjectId('5908971e42e9c49335e83ead'), u'type': u'article', u'id': u'journals/ipl/Engelfriet07'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'On Tree Transducers for Partial Functions.', u'author': [u'Joost Engelfriet'], u'year': 1978, u'_id': ObjectId('5908971e42e9c49335e83f4b'), u'type': u'article', u'id': u'journals/ipl/Engelfriet78'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'Copying Theorems.', u'author': [u'Joost Engelfriet', u'Sven Skyum'], u'year': 1976, u'_id': ObjectId('5908971e42e9c49335e84a28'), u'type': u'article', u'id': u'journals/ipl/EngelfrietS76'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'An exercise in structural congruence.', u'author': [u'Joost Engelfriet', u'Tjalling Gelsema'], u'year': 2007, u'_id': ObjectId('5908971e42e9c49335e84df5'), u'type': u'article', u'id': u'journals/ipl/EngelfrietG07'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'A Note on Infinite Trees.', u'author': [u'Joost Engelfriet'], u'year': 1972, u'_id': ObjectId('5908971e42e9c49335e84fcf'), u'type': u'article', u'id': u'journals/ipl/Engelfriet72'}\n",
      "\n",
      "  {u'container': u'Inf. Process. Lett.', u'title': u'Prefix and Equality Languages of Rational Functions are Co-Context-Free.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1988, u'_id': ObjectId('5908971e42e9c49335e8516e'), u'type': u'article', u'id': u'journals/ipl/EngelfrietH88'}\n",
      "\n",
      "  {u'container': u'SIGACT News', u'title': u'The complexity of the circularity problem for attribute grammars: a note on a counterexample for a simpler construction.', u'author': [u'Joost Engelfriet'], u'year': 1989, u'_id': ObjectId('5908971f42e9c49335e92845'), u'type': u'article', u'id': u'journals/sigact/Engelfriet89'}\n",
      "\n",
      "  {u'container': u'J. Algorithms', u'title': u'Domino Treewidth.', u'author': [u'Hans L. Bodlaender', u'Joost Engelfriet'], u'year': 1997, u'_id': ObjectId('5908972142e9c49335e9dab9'), u'type': u'article', u'id': u'journals/jal/BodlaenderE97'}\n",
      "\n",
      "  {u'container': u'Information and Control', u'title': u'A Tranlsational Theorem for the Class of EOL Languages', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1981, u'_id': ObjectId('5908972142e9c49335e9ea67'), u'type': u'article', u'id': u'journals/iandc/EngelfrietR81'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'The Power to Two-Way Deterministic Checking Stack Automata', u'author': [u'Joost Engelfriet'], u'year': 1989, u'_id': ObjectId('5908972142e9c49335e9ebec'), u'type': u'article', u'id': u'journals/iandc/Engelfriet89'}\n",
      "\n",
      "  {u'container': u'Information and Control', u'title': u'Equality Languages and Fixed Point Languages', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1979, u'_id': ObjectId('5908972142e9c49335e9edf9'), u'type': u'article', u'id': u'journals/iandc/EngelfrietR79'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Linear Graph Grammars: Power and Complexity', u'author': [u'Joost Engelfriet', u'George Leih'], u'year': 1989, u'_id': ObjectId('5908972142e9c49335e9ee09'), u'type': u'article', u'id': u'journals/iandc/EngelfrietL89'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Macro Tree Transducers, Attribute Grammars, and MSO Definable Tree Translations.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 1999, u'_id': ObjectId('5908972142e9c49335e9eebf'), u'type': u'article', u'id': u'journals/iandc/EngelfrietM99'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Look-Ahead on Pushdowns', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1987, u'_id': ObjectId('5908972142e9c49335e9efe1'), u'type': u'article', u'id': u'journals/iandc/EngelfrietV87'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Iterated Stack Automata and Complexity Classes', u'author': [u'Joost Engelfriet'], u'year': 1991, u'_id': ObjectId('5908972142e9c49335e9f024'), u'type': u'article', u'id': u'journals/iandc/Engelfriet91'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'The generative power of delegation networks.', u'author': [u'Frank Drewes', u'Joost Engelfriet'], u'year': 2015, u'_id': ObjectId('5908972142e9c49335e9f03a'), u'type': u'article', u'id': u'journals/iandc/DrewesE15'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Decidability of the Finiteness of Ranges of Tree Transductions.', u'author': [u'Frank Drewes', u'Joost Engelfriet'], u'year': 1998, u'_id': ObjectId('5908972142e9c49335e9f0a8'), u'type': u'article', u'id': u'journals/iandc/DrewesE98'}\n",
      "\n",
      "  {u'container': u'Information and Control', u'title': u'Passes and Paths of Attributive Grammars', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1981, u'_id': ObjectId('5908972142e9c49335e9f126'), u'type': u'article', u'id': u'journals/iandc/EngelfrietF81'}\n",
      "\n",
      "  {u'container': u'Information and Control', u'title': u'Bounded Nesting in Macro Grammars', u'author': [u'Joost Engelfriet', u'Giora Slutzki'], u'year': 1979, u'_id': ObjectId('5908972142e9c49335e9f19f'), u'type': u'article', u'id': u'journals/iandc/EngelfrietS79'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'A Comparison of Boundary Graph Grammars and Context-Free Hypergraph Grammars', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1990, u'_id': ObjectId('5908972142e9c49335e9f32a'), u'type': u'article', u'id': u'journals/iandc/EngelfrietR90'}\n",
      "\n",
      "  {u'container': u'Inf. Comput.', u'title': u'Derivation Trees of Ground Term Rewriting Systems.', u'author': [u'Joost Engelfriet'], u'year': 1999, u'_id': ObjectId('5908972142e9c49335e9f4d5'), u'type': u'article', u'id': u'journals/iandc/Engelfriet99'}\n",
      "\n",
      "  {u'container': u'J. ACM', u'title': u'Stack Machines and Classes of Nonnested Macro Languages.', u'author': [u'Joost Engelfriet', u'Erik Meineche Schmidt', u'Jan van Leeuwen'], u'year': 1980, u'_id': ObjectId('5908972442e9c49335eb20df'), u'type': u'article', u'id': u'journals/jacm/EngelfrietSL80'}\n",
      "\n",
      "  {u'container': u'J. ACM', u'title': u'Fixed Point Languages, Equality Languages, and Representation of Recursively Enumerable Languages.', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1980, u'_id': ObjectId('5908972442e9c49335eb2168'), u'type': u'article', u'id': u'journals/jacm/EngelfrietR80'}\n",
      "\n",
      "  {u'container': u'J. ACM', u'title': u'Passes, sweeps, and visits in attribute grammars.', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1989, u'_id': ObjectId('5908972442e9c49335eb2639'), u'type': u'article', u'id': u'journals/jacm/EngelfrietF89'}\n",
      "\n",
      "  {u'container': u'Mathematical Systems Theory', u'title': u'Three Hierarchies of Transducers.', u'author': [u'Joost Engelfriet'], u'year': 1982, u'_id': ObjectId('5908972442e9c49335eb2775'), u'type': u'article', u'id': u'journals/mst/Engelfriet82'}\n",
      "\n",
      "  {u'container': u'Theory Comput. Syst.', u'title': u'Composition Closure of Linear Extended Top-down Tree Transducers.', u'author': [u'Joost Engelfriet', u'Zoltn Flp 0001', u'Andreas Maletti'], u'year': 2017, u'_id': ObjectId('5908972442e9c49335eb2780'), u'type': u'article', u'id': u'journals/mst/EngelfrietFM17'}\n",
      "\n",
      "  {u'container': u'Theory Comput. Syst.', u'title': u'Clique-Width for 4-Vertex Forbidden Subgraphs.', u'author': [u'Andreas Brandstdt', u'Joost Engelfriet', u'Hong-Oanh Le', u'Vadim V. Lozin'], u'year': 2006, u'_id': ObjectId('5908972442e9c49335eb27b1'), u'type': u'article', u'id': u'journals/mst/BrandstadtELL06'}\n",
      "\n",
      "  {u'container': u'Theory Comput. Syst.', u'title': u'Erratum to: \"Top-down Tree Transducers with Regular Look-ahead\".', u'author': [u'Joost Engelfriet'], u'year': 2016, u'_id': ObjectId('5908972442e9c49335eb28b0'), u'type': u'article', u'id': u'journals/mst/Engelfriet16'}\n",
      "\n",
      "  {u'container': u'Mathematical Systems Theory', u'title': u'A Logical Characterization of the Sets of Hypergraphs Defined by Hyperedge Replacement Grammars.', u'author': [u'Bruno Courcelle', u'Joost Engelfriet'], u'year': 1995, u'_id': ObjectId('5908972442e9c49335eb2996'), u'type': u'article', u'id': u'journals/mst/CourcelleE95'}\n",
      "\n",
      "  {u'container': u'Mathematical Systems Theory', u'title': u'Bottom-up and Top-down Tree Transformations - A Comparison.', u'author': [u'Joost Engelfriet'], u'year': 1975, u'_id': ObjectId('5908972442e9c49335eb2b72'), u'type': u'article', u'id': u'journals/mst/Engelfriet75'}\n",
      "\n",
      "  {u'container': u'Mathematical Systems Theory', u'title': u'Top-down Tree Transducers with Regular Look-ahead.', u'author': [u'Joost Engelfriet'], u'year': 1977, u'_id': ObjectId('5908972442e9c49335eb2e26'), u'type': u'article', u'id': u'journals/mst/Engelfriet77'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Tree Transducers, L Systems, and Two-Way Machines.', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg', u'Giora Slutzki'], u'year': 1980, u'_id': ObjectId('5908972542e9c49335ebd71b'), u'type': u'article', u'id': u'journals/jcss/EngelfrietRS80'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'The Equivalence of Bottom-Up and Top-Down Tree-to-Graph Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1998, u'_id': ObjectId('5908972542e9c49335ebd7eb'), u'type': u'article', u'id': u'journals/jcss/EngelfrietV98'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Deciding equivalence of top-down XML transformations in polynomial time.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth', u'Helmut Seidl'], u'year': 2009, u'_id': ObjectId('5908972542e9c49335ebd845'), u'type': u'article', u'id': u'journals/jcss/EngelfrietMS09'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Handle-Rewriting Hypergraph Grammars.', u'author': [u'Bruno Courcelle', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1993, u'_id': ObjectId('5908972542e9c49335ebd8e9'), u'type': u'article', u'id': u'journals/jcss/CourcelleER93'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Macro Tree Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1985, u'_id': ObjectId('5908972542e9c49335ebd92e'), u'type': u'article', u'id': u'journals/jcss/EngelfrietV85'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Boundary Graph Grammars with Dynamic Edge Relabeling.', u'author': [u'Joost Engelfriet', u'George Leih', u'Emo Welzl'], u'year': 1990, u'_id': ObjectId('5908972542e9c49335ebda74'), u'type': u'article', u'id': u'journals/jcss/EngelfrietLW90'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'IO and OI. II.', u'author': [u'Joost Engelfriet', u'Erik Meineche Schmidt'], u'year': 1978, u'_id': ObjectId('5908972542e9c49335ebda9b'), u'type': u'article', u'id': u'journals/jcss/EngelfrietS78'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Hypergraph Languages of Bounded Degree.', u'author': [u'Joost Engelfriet', u'Linda Heyker'], u'year': 1994, u'_id': ObjectId('5908972542e9c49335ebdb0c'), u'type': u'article', u'id': u'journals/jcss/EngelfrietH94'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Logical Description of Contex-Free Graph Languages.', u'author': [u'Joost Engelfriet', u'Vincent van Oostrom'], u'year': 1997, u'_id': ObjectId('5908972542e9c49335ebdb3f'), u'type': u'article', u'id': u'journals/jcss/EngelfrietO97'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'IO and OI. I.', u'author': [u'Joost Engelfriet', u'Erik Meineche Schmidt'], u'year': 1977, u'_id': ObjectId('5908972542e9c49335ebdb46'), u'type': u'article', u'id': u'journals/jcss/EngelfrietS77'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Determinacy and rewriting of functional top-down and MSO tree transformations.', u'author': [u'Michael Benedikt', u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2017, u'_id': ObjectId('5908972542e9c49335ebdbb9'), u'type': u'article', u'id': u'journals/jcss/BenediktEM17'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'The Copying Power of One-State Tree Transducers.', u'author': [u'Joost Engelfriet', u'Sven Skyum'], u'year': 1982, u'_id': ObjectId('5908972542e9c49335ebdc45'), u'type': u'article', u'id': u'journals/jcss/EngelfrietS82'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Regular Description of Context-Free Graph Languages.', u'author': [u'Joost Engelfriet', u'Vincent van Oostrom'], u'year': 1996, u'_id': ObjectId('5908972542e9c49335ebdc4c'), u'type': u'article', u'id': u'journals/jcss/EngelfrietO96'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Hierarchies of Hyper-AFLs.', u'author': [u'Joost Engelfriet'], u'year': 1985, u'_id': ObjectId('5908972542e9c49335ebdc89'), u'type': u'article', u'id': u'journals/jcss/Engelfriet85'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Context Free Normal Systems and ETOL Systems.', u'author': [u'Andrzej Ehrenfeucht', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1983, u'_id': ObjectId('5908972542e9c49335ebdcff'), u'type': u'article', u'id': u'journals/jcss/EhrenfeuchtER83'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Branching synchronization grammars with nested tables.', u'author': [u'Frank Drewes', u'Joost Engelfriet'], u'year': 2004, u'_id': ObjectId('5908972542e9c49335ebdec2'), u'type': u'article', u'id': u'journals/jcss/DrewesE04'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'A Comparison of Tree Transductions Defined by Monadic Second Order Logic and by Attribute Grammars.', u'author': [u'Roderick Bloem', u'Joost Engelfriet'], u'year': 2000, u'_id': ObjectId('5908972542e9c49335ebdee8'), u'type': u'article', u'id': u'journals/jcss/BloemE00'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Simple Multi-Visit Attribute Grammars.', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1982, u'_id': ObjectId('5908972542e9c49335ebdf72'), u'type': u'article', u'id': u'journals/jcss/EngelfrietF82'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Extended Macro Grammars and Stack Controlled Machines.', u'author': [u'Joost Engelfriet', u'Giora Slutzki'], u'year': 1984, u'_id': ObjectId('5908972542e9c49335ebe08a'), u'type': u'article', u'id': u'journals/jcss/EngelfrietS84'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'The Translation Power of Top-Down Tree-to-Graph Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1994, u'_id': ObjectId('5908972542e9c49335ebe0b3'), u'type': u'article', u'id': u'journals/jcss/EngelfrietV94'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Output String Languages of Compositions of Deterministic Macro Tree Transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2002, u'_id': ObjectId('5908972542e9c49335ebe0ca'), u'type': u'article', u'id': u'journals/jcss/EngelfrietM02'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'Finite Languages for the Representation of Finite Graphs.', u'author': [u'Andrzej Ehrenfeucht', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1996, u'_id': ObjectId('5908972542e9c49335ebe0e8'), u'type': u'article', u'id': u'journals/jcss/EhrenfeuchtER96'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'The Complexity of Regular DNLC Graph Languages.', u'author': [u'IJsbrand Jan Aalbersberg', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1990, u'_id': ObjectId('5908972542e9c49335ebe117'), u'type': u'article', u'id': u'journals/jcss/AalbersbergER90'}\n",
      "\n",
      "  {u'container': u'J. Comput. Syst. Sci.', u'title': u'The String Generating Power of Context-Free Hypergraph Grammars.', u'author': [u'Joost Engelfriet', u'Linda Heyker'], u'year': 1991, u'_id': ObjectId('5908972542e9c49335ebe172'), u'type': u'article', u'id': u'journals/jcss/EngelfrietH91'}\n",
      "\n",
      "  {u'container': u'Bulletin of the EATCS', u'title': u'The non-computability of computability.', u'author': [u'Joost Engelfriet'], u'year': 1985, u'_id': ObjectId('5908972742e9c49335eca854'), u'type': u'article', u'id': u'journals/eatcs/Engelfriet85'}\n",
      "\n",
      "  {u'container': u'Bulletin of the EATCS', u'title': u'Book: Graph Structure and Monadic Second-Order Logic. A Language-Theoretic Approach.', u'author': [u'Bruno Courcelle', u'Joost Engelfriet'], u'year': 2012, u'_id': ObjectId('5908972742e9c49335eca9ce'), u'type': u'article', u'id': u'journals/eatcs/CourcelleE12'}\n",
      "\n",
      "  {u'container': u'Bulletin of the EATCS', u'title': u'Reverse Twin Shuffles.', u'author': [u'Joost Engelfriet'], u'year': 1996, u'_id': ObjectId('5908972742e9c49335ecaa53'), u'type': u'article', u'id': u'journals/eatcs/Engelfriet96'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'Context-Free Grammars with Storage.', u'author': [u'Joost Engelfriet'], u'year': 2014, u'_id': ObjectId('5908972c42e9c49335ef0607'), u'type': u'article', u'id': u'journals/corr/Engelfriet14'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'Look-Ahead Removal for Top-Down Tree Transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth', u'Helmut Seidl'], u'year': 2013, u'_id': ObjectId('5908972d42e9c49335ef2320'), u'type': u'article', u'id': u'journals/corr/EngelfrietMS13'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'The Equivalence Problem for Deterministic MSO Tree Transducers is Decidable', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2005, u'_id': ObjectId('5908972d42e9c49335ef4de8'), u'type': u'article', u'id': u'journals/corr/abs-cs-0506014'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'Tree Automata and Tree Grammars.', u'author': [u'Joost Engelfriet'], u'year': 2015, u'_id': ObjectId('5908972e42e9c49335efb936'), u'type': u'article', u'id': u'journals/corr/Engelfriet15'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'MSO definable string transductions and two-way finite state transducers', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1999, u'_id': ObjectId('5908973042e9c49335f07548'), u'type': u'article', u'id': u'journals/corr/cs-LO-9906007'}\n",
      "\n",
      "  {u'container': u'CoRR', u'title': u'Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 2007, u'_id': ObjectId('5908973042e9c49335f09655'), u'type': u'article', u'id': u'journals/corr/abs-cs-0703079'}\n",
      "\n",
      "  {u'container': u'ITA', u'title': u'Complexity of boundary graph languages.', u'author': [u'Joost Engelfriet', u'George Leih'], u'year': 1990, u'_id': ObjectId('5908973342e9c49335f17f21'), u'type': u'article', u'id': u'journals/ita/EngelfrietL90'}\n",
      "\n",
      "  {u'container': u'ACM Trans. Comput. Log.', u'title': u'MSO definable string transductions and two-way finite-state transducers.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 2001, u'_id': ObjectId('5908973342e9c49335f1a059'), u'type': u'article', u'id': u'journals/tocl/EngelfrietH01'}\n",
      "\n",
      "  {u'container': u'Journal of Automata, Languages and Combinatorics', u'title': u'Bottom-Up and Top-Down Tree Series Transformations.', u'author': [u'Joost Engelfriet', u'Zoltn Flp 0001', u'Heiko Vogler'], u'year': 2002, u'_id': ObjectId('5908973b42e9c49335f4ff83'), u'type': u'article', u'id': u'journals/jalc/EngelfrietFV02'}\n",
      "\n",
      "  {u'container': u'Fundam. Inform.', u'title': u'Finitary Compositions of Two-way Finite-State Transductions.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 2007, u'_id': ObjectId('5908973d42e9c49335f61ca5'), u'type': u'article', u'id': u'journals/fuin/EngelfrietH07'}\n",
      "\n",
      "  {u'container': u'Fundam. Inform.', u'title': u'Grammatical Codes of Trees and Terminally Coded Grammars.', u'author': [u'Andrzej Ehrenfeucht', u'Joost Engelfriet', u'Paulien ten Pas', u'Grzegorz Rozenberg'], u'year': 1995, u'_id': ObjectId('5908973e42e9c49335f62287'), u'type': u'article', u'id': u'journals/fuin/EhrenfeuchtEPR95'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Modular Tree Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1991, u'_id': ObjectId('5908973f42e9c49335f6eee6'), u'type': u'article', u'id': u'journals/tcs/EngelfrietV91'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Nonterminal Separation in Graph Grammars.', u'author': [u'Joost Engelfriet', u'George Leih', u'Grzegorz Rozenberg'], u'year': 1991, u'_id': ObjectId('5908974042e9c49335f6fafa'), u'type': u'article', u'id': u'journals/tcs/EngelfrietLR91'}\n",
      "\n",
      "  {u'container': u'Electr. Notes Theor. Comput. Sci.', u'title': u'As Time Goes By II: More Automatic Complexity Analysis of Concurrent Rule Programs.', u'author': [u'Joost Engelfriet', u'Heiko Vogler', u'Thom W. Frhwirth'], u'year': 2001, u'_id': ObjectId('5908974042e9c49335f6fc03'), u'type': u'article', u'id': u'journals/tcs/Fruhwirth01'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Characterization and Complexity of Uniformly Non Primitive Labeled 2-Structures.', u'author': [u'Joost Engelfriet', u'Tero Harju', u'Andrzej Proskurowski', u'Grzegorz Rozenberg'], u'year': 1996, u'_id': ObjectId('5908974042e9c49335f6fc38'), u'type': u'article', u'id': u'journals/tcs/EngelfrietHPR96'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'X-Automata on omega-Words.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1993, u'_id': ObjectId('5908974042e9c49335f6fce9'), u'type': u'article', u'id': u'journals/tcs/EngelfrietH93'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'A Regular Characterization of Graph Languages Definable in Monadic Second-Order Logic.', u'author': [u'Joost Engelfriet'], u'year': 1991, u'_id': ObjectId('5908974042e9c49335f700af'), u'type': u'article', u'id': u'journals/tcs/Engelfriet91'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Determinacy - (Observation Equivalence = Trace Equivalence).', u'author': [u'Joost Engelfriet'], u'year': 1985, u'_id': ObjectId('5908974042e9c49335f702f3'), u'type': u'article', u'id': u'journals/tcs/Engelfriet85'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Pushdown Machines for the Macro Tree Transducer.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1986, u'_id': ObjectId('5908974042e9c49335f7064a'), u'type': u'article', u'id': u'journals/tcs/EngelfrietV86'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Look-ahead removal for total deterministic top-down tree transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth', u'Helmut Seidl'], u'year': 2016, u'_id': ObjectId('5908974042e9c49335f708d8'), u'type': u'article', u'id': u'journals/tcs/EngelfrietMS16'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Surface Tree Languages and Parallel Derivation Trees.', u'author': [u'Joost Engelfriet'], u'year': 1976, u'_id': ObjectId('5908974042e9c49335f709c8'), u'type': u'article', u'id': u'journals/tcs/Engelfriet76'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Structural inclusion in the pi-calculus with replication.', u'author': [u'Joost Engelfriet', u'Tjalling Gelsema'], u'year': 2001, u'_id': ObjectId('5908974042e9c49335f709e2'), u'type': u'article', u'id': u'journals/tcs/EngelfrietG01'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Nonterminal Bounded NLC Graph Grammars.', u'author': [u'Joost Engelfriet', u'George Leih'], u'year': 1988, u'_id': ObjectId('5908974042e9c49335f713cb'), u'type': u'article', u'id': u'journals/tcs/EngelfrietL88'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Multisets and Structural Congruence of the pi-Calculus with Replication.', u'author': [u'Joost Engelfriet', u'Tjalling Gelsema'], u'year': 1999, u'_id': ObjectId('5908974042e9c49335f71781'), u'type': u'article', u'id': u'journals/tcs/EngelfrietG99'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'Iterating Iterated Substitution.', u'author': [u'Joost Engelfriet'], u'year': 1977, u'_id': ObjectId('5908974042e9c49335f7181b'), u'type': u'article', u'id': u'journals/tcs/Engelfriet77'}\n",
      "\n",
      "  {u'container': u'Theor. Comput. Sci.', u'title': u'A Multiset Semantics for the pi-Calculus with Replication.', u'author': [u'Joost Engelfriet'], u'year': 1996, u'_id': ObjectId('5908974042e9c49335f719e3'), u'type': u'article', u'id': u'journals/tcs/Engelfriet96'}\n",
      "\n",
      "  {u'container': u'Acta Cybern.', u'title': u'Trips on Trees.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom', u'Jan-Pascal van Best'], u'year': 1999, u'_id': ObjectId('5908974242e9c49335f7eb76'), u'type': u'article', u'id': u'journals/actaC/EngelfrietHB99'}\n",
      "\n",
      "  {u'container': u'Logical Methods in Computer Science', u'title': u'Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 2007, u'_id': ObjectId('5908974342e9c49335f84acf'), u'type': u'article', u'id': u'journals/lmcs/EngelfrietH07'}\n",
      "\n",
      "  {u'container': u'SIAM J. Comput.', u'title': u'The complexity of Languages Generated by Attribute Grammars.', u'author': [u'Joost Engelfriet'], u'year': 1986, u'_id': ObjectId('5908974642e9c49335f9c4a2'), u'type': u'article', u'id': u'journals/siamcomp/Engelfriet86'}\n",
      "\n",
      "  {u'container': u'SIAM J. Comput.', u'title': u'Macro Tree Translations of Linear Size Increase are MSO Definable.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2003, u'_id': ObjectId('5908974642e9c49335f9ca42'), u'type': u'article', u'id': u'journals/siamcomp/EngelfrietM03'}\n",
      "\n",
      "  {u'container': u'Logic in the Theory and Practice of Lawmaking', u'title': u'Graph Structure and Monadic Second-Order Logic - A Language-Theoretic Approach.', u'author': [u'Bruno Courcelle', u'Joost Engelfriet'], u'year': 2012, u'_id': ObjectId('5908974842e9c49335fa8202'), u'type': u'book', u'id': u'books/daglib/0030804'}\n",
      "\n",
      "  {u'container': u'Advances in Multiresolution for Geometric Modelling', u'title': u'Simple Program Schemes and Formal Languages', u'author': [u'Joost Engelfriet'], u'year': 1974, u'_id': ObjectId('5908974842e9c49335faa44d'), u'type': u'book', u'id': u'books/sp/Engelfriet74'}\n",
      "\n",
      "  {u'container': u'Formal and Natural Computing', u'title': u'The Delta Operation: From Strings to Trees to Strings.', u'author': [u'Joost Engelfriet'], u'year': 2002, u'_id': ObjectId('5908974c42e9c49335fc5049'), u'type': u'inproceedings', u'id': u'conf/birthday/Engelfriet02'}\n",
      "\n",
      "  {u'container': u'Jewels are Forever', u'title': u'Tree-Walking Pebble Automata.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1999, u'_id': ObjectId('5908974c42e9c49335fc54b0'), u'type': u'inproceedings', u'id': u'conf/birthday/EngelfrietH99'}\n",
      "\n",
      "  {u'container': u'Structures in Logic and Computer Science', u'title': u'Monadic Second Order Logic and Node Relations on Graphs and Trees.', u'author': [u'Roderick Bloem', u'Joost Engelfriet'], u'year': 1997, u'_id': ObjectId('5908974c42e9c49335fc54f1'), u'type': u'inproceedings', u'id': u'conf/birthday/BloemE97'}\n",
      "\n",
      "  {u'container': u'Results and Trends in Theoretical Computer Science', u'title': u'Deciding the NTS Property of Context-Free Grammars.', u'author': [u'Joost Engelfriet'], u'year': 1994, u'_id': ObjectId('5908974c42e9c49335fc5942'), u'type': u'inproceedings', u'id': u'conf/birthday/Engelfriet94'}\n",
      "\n",
      "  {u'container': u'ACL (1)', u'title': u'Strong Lexicalization of Tree Adjoining Grammars.', u'author': [u'Andreas Maletti', u'Joost Engelfriet'], u'year': 2012, u'_id': ObjectId('5908974c42e9c49335fc6d04'), u'type': u'inproceedings', u'id': u'conf/acl/MalettiE12'}\n",
      "\n",
      "  {u'container': u'WG', u'title': u'Domino Treewith (Extended Abstract).', u'author': [u'Hans L. Bodlaender', u'Joost Engelfriet'], u'year': 1994, u'_id': ObjectId('5908975942e9c49335014df4'), u'type': u'inproceedings', u'id': u'conf/wg/BodlaenderE94'}\n",
      "\n",
      "  {u'container': u'CONCUR', u'title': u'A Multiset Semantics for the pi-Calculus with Replication.', u'author': [u'Joost Engelfriet'], u'year': 1993, u'_id': ObjectId('5908975942e9c49335015f6b'), u'type': u'inproceedings', u'id': u'conf/concur/Engelfriet93'}\n",
      "\n",
      "  {u'container': u'CAAP', u'title': u'Regular Characterizations of Macro Tree Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1984, u'_id': ObjectId('5908975e42e9c49335032793'), u'type': u'inproceedings', u'id': u'conf/caap/EngelfrietV84'}\n",
      "\n",
      "  {u'container': u'CAAP', u'title': u'Graph Grammars and Tree Transducers.', u'author': [u'Joost Engelfriet'], u'year': 1994, u'_id': ObjectId('5908975e42e9c49335032840'), u'type': u'inproceedings', u'id': u'conf/caap/Engelfriet94'}\n",
      "\n",
      "  {u'container': u'Petri Nets', u'title': u'Elementary Net Systems.', u'author': [u'Grzegorz Rozenberg', u'Joost Engelfriet'], u'year': 1996, u'_id': ObjectId('5908976042e9c4933503e7fc'), u'type': u'inproceedings', u'id': u'conf/ac/RozenbergE96'}\n",
      "\n",
      "  {u'container': u'Method and tools for compiler construction', u'title': u'Attribute Grammars: Attribute Evaluation Methods.', u'author': [u'Joost Engelfriet'], u'year': 1983, u'_id': ObjectId('5908976042e9c4933503e8b9'), u'type': u'inproceedings', u'id': u'conf/ac/Engelfriet83'}\n",
      "\n",
      "  {u'container': u'REX Workshop', u'title': u'Net-Based Description Of Parallel Object-Based Systems, or POTs and POPs.', u'author': [u'Joost Engelfriet', u'George Leih', u'Grzegorz Rozenberg'], u'year': 1990, u'_id': ObjectId('5908976442e9c4933505908a'), u'type': u'inproceedings', u'id': u'conf/rex/EngelfrietLR90'}\n",
      "\n",
      "  {u'container': u'STACS', u'title': u'Nested Pebbles and Transitive Closure.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 2006, u'_id': ObjectId('5908976442e9c4933505a97b'), u'type': u'inproceedings', u'id': u'conf/stacs/EngelfrietH06'}\n",
      "\n",
      "  {u'container': u'STACS', u'title': u'Characterizing and Deciding MSO-Definability of Macro Tree Transductions.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2000, u'_id': ObjectId('5908976442e9c4933505a99a'), u'type': u'inproceedings', u'id': u'conf/stacs/EngelfrietM00'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'Restricting the complexity of regular DNLC languages.', u'author': [u'IJsbrand Jan Aalbersberg', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1986, u'_id': ObjectId('5908976742e9c49335064750'), u'type': u'inproceedings', u'id': u'conf/gg/AalbersbergER86'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'Context-free Handle-rewriting Hypergraph Grammars.', u'author': [u'Bruno Courcelle', u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1990, u'_id': ObjectId('5908976742e9c49335064788'), u'type': u'inproceedings', u'id': u'conf/gg/CourcelleER90'}\n",
      "\n",
      "  {u'container': u'Handbook of Graph Grammars', u'title': u'Node Replacement Graph Grammars.', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1997, u'_id': ObjectId('5908976742e9c493350647a8'), u'type': u'inproceedings', u'id': u'conf/gg/EngelfrietR97'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'A Characterization of Context-Free NCE Graph Languages by Monadic Second-Order Logic on Trees.', u'author': [u'Joost Engelfriet'], u'year': 1990, u'_id': ObjectId('5908976742e9c493350647c4'), u'type': u'inproceedings', u'id': u'conf/gg/Engelfriet90'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'The Term Generating Power of Context-Free Hypergraph Grammars.', u'author': [u'Joost Engelfriet', u'Linda Heyker'], u'year': 1990, u'_id': ObjectId('5908976742e9c493350647e2'), u'type': u'inproceedings', u'id': u'conf/gg/EngelfrietH90'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'Graph Grammars Based on Node Rewriting: An Introduction to NLC Graph Grammars.', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1990, u'_id': ObjectId('5908976742e9c493350647f9'), u'type': u'inproceedings', u'id': u'conf/gg/EngelfrietR90'}\n",
      "\n",
      "  {u'container': u'Graph-Grammars and Their Application to Computer Science', u'title': u'Apex Graph Grammars.', u'author': [u'Joost Engelfriet', u'George Leih', u'Grzegorz Rozenberg'], u'year': 1986, u'_id': ObjectId('5908976742e9c493350647fd'), u'type': u'inproceedings', u'id': u'conf/gg/EngelfrietLR86'}\n",
      "\n",
      "  {u'container': u'PODS', u'title': u'XML transformation by tree-walking transducers with invisible pebbles.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom', u'Bart Samwel'], u'year': 2007, u'_id': ObjectId('5908976a42e9c4933507abfb'), u'type': u'inproceedings', u'id': u'conf/pods/EngelfrietHS07'}\n",
      "\n",
      "  {u'container': u'STOC', u'title': u'Iterated Pushdown Automata and Complexity Classes', u'author': [u'Joost Engelfriet'], u'year': 1983, u'_id': ObjectId('5908976b42e9c493350860f3'), u'type': u'inproceedings', u'id': u'conf/stoc/Engelfriet83'}\n",
      "\n",
      "  {u'container': u'STOC', u'title': u'Tree Transducers, L Systems and Two-Way Machines (Extended Abstract)', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg', u'Giora Slutzki'], u'year': 1978, u'_id': ObjectId('5908976b42e9c49335086545'), u'type': u'inproceedings', u'id': u'conf/stoc/EngelfrietRS78'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Characterization of High Level Tree Transducers.', u'author': [u'Joost Engelfriet', u'Heiko Vogler'], u'year': 1985, u'_id': ObjectId('5908976c42e9c4933508cf06'), u'type': u'inproceedings', u'id': u'conf/icalp/EngelfrietV85'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'A Greibach Normal Form for Context-free Graph Grammars.', u'author': [u'Joost Engelfriet'], u'year': 1992, u'_id': ObjectId('5908976c42e9c4933508cfaf'), u'type': u'inproceedings', u'id': u'conf/icalp/Engelfriet92'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Two-Way Finite State Transducers and Monadic Second-Order Logic.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1999, u'_id': ObjectId('5908976c42e9c4933508d30d'), u'type': u'inproceedings', u'id': u'conf/icalp/EngelfrietH99'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Passes, Sweeps and Visits.', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1981, u'_id': ObjectId('5908976c42e9c4933508d387'), u'type': u'inproceedings', u'id': u'conf/icalp/EngelfrietF81'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Formal Properties of One-Visit and Multi-Pass Attribute Grammars.', u'author': [u'Joost Engelfriet', u'Gilberto Fil'], u'year': 1980, u'_id': ObjectId('5908976c42e9c4933508d5e4'), u'type': u'inproceedings', u'id': u'conf/icalp/EngelfrietF80'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Automata with Storage on Infinite Words.', u'author': [u'Joost Engelfriet', u'Hendrik Jan Hoogeboom'], u'year': 1989, u'_id': ObjectId('5908976c42e9c4933508d87d'), u'type': u'inproceedings', u'id': u'conf/icalp/EngelfrietH89'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Translation of Simple Program Schemes.', u'author': [u'Joost Engelfriet'], u'year': 1972, u'_id': ObjectId('5908976c42e9c4933508d8ec'), u'type': u'inproceedings', u'id': u'conf/icalp/Engelfriet72'}\n",
      "\n",
      "  {u'container': u'ICALP', u'title': u'Macro Grammars, Lindenmayer Systems and Other Copying Devices.', u'author': [u'Joost Engelfriet'], u'year': 1977, u'_id': ObjectId('5908976c42e9c4933508d935'), u'type': u'inproceedings', u'id': u'conf/icalp/Engelfriet77'}\n",
      "\n",
      "  {u'container': u'TAGT', u'title': u'Tree Languages Generated be Context-Free Graph Grammars.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 1998, u'_id': ObjectId('5908976f42e9c4933509b329'), u'type': u'inproceedings', u'id': u'conf/tagt/EngelfrietM98'}\n",
      "\n",
      "  {u'container': u'TAGT', u'title': u'Concatenation of Graphs.', u'author': [u'Joost Engelfriet', u'Jan Joris Vereijken'], u'year': 1994, u'_id': ObjectId('5908976f42e9c4933509b356'), u'type': u'inproceedings', u'id': u'conf/tagt/EngelfrietV94'}\n",
      "\n",
      "  {u'container': u'FOCS', u'title': u'Equality Languages, Fixed Point Languages and Representations of Recursively Enumerable Languages', u'author': [u'Joost Engelfriet', u'Grzegorz Rozenberg'], u'year': 1978, u'_id': ObjectId('5908977642e9c493350c31b5'), u'type': u'inproceedings', u'id': u'conf/focs/EngelfrietR78'}\n",
      "\n",
      "  {u'container': u'MFCS', u'title': u'Two-Way Finite State Transducers with Nested Pebbles.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2002, u'_id': ObjectId('5908977e42e9c493350f4fbb'), u'type': u'inproceedings', u'id': u'conf/mfcs/EngelfrietM02'}\n",
      "\n",
      "  {u'container': u'MFCS', u'title': u'Determinacy and Rewriting of Top-Down and MSO Tree Transformations.', u'author': [u'Michael Benedikt', u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2013, u'_id': ObjectId('5908977e42e9c493350f5079'), u'type': u'inproceedings', u'id': u'conf/mfcs/BenediktEM13'}\n",
      "\n",
      "  {u'container': u'FSTTCS', u'title': u'The Equivalence Problem for Deterministic MSO Tree Transducers Is Decidable.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2005, u'_id': ObjectId('5908978542e9c4933512613f'), u'type': u'inproceedings', u'id': u'conf/fsttcs/EngelfrietM05'}\n",
      "\n",
      "  {u'container': u'Developments in Language Theory', u'title': u'Branching Grammars: A Generalization of ET0L Systems.', u'author': [u'Frank Drewes', u'Joost Engelfriet'], u'year': 2003, u'_id': ObjectId('5908978842e9c4933513381f'), u'type': u'inproceedings', u'id': u'conf/dlt/DrewesE03'}\n",
      "\n",
      "  {u'container': u'Developments in Language Theory', u'title': u'Hierarchies of String Languages Generated by Deterministic Tree Transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth'], u'year': 2001, u'_id': ObjectId('5908978842e9c493351338f3'), u'type': u'inproceedings', u'id': u'conf/dlt/EngelfrietM01'}\n",
      "\n",
      "  {u'container': u'Developments in Language Theory', u'title': u'Extended Multi Bottom-Up Tree Transducers.', u'author': [u'Joost Engelfriet', u'Eric Lilin', u'Andreas Maletti'], u'year': 2008, u'_id': ObjectId('5908978842e9c49335133983'), u'type': u'inproceedings', u'id': u'conf/dlt/EngelfrietLM08'}\n",
      "\n",
      "  {u'container': u'Developments in Language Theory', u'title': u'How to Remove the Look-Ahead of Top-Down Tree Transducers.', u'author': [u'Joost Engelfriet', u'Sebastian Maneth', u'Helmut Seidl'], u'year': 2014, u'_id': ObjectId('5908978842e9c49335133a40'), u'type': u'inproceedings', u'id': u'conf/dlt/EngelfrietMS14'}\n",
      "\n",
      "  {u'container': u'FCT', u'title': u'Context-Free NCE Graph Grammars.', u'author': [u'Joost Engelfriet'], u'year': 1989, u'_id': ObjectId('5908979442e9c4933518448d'), u'type': u'inproceedings', u'id': u'conf/fct/Engelfriet89'}\n",
      "\n",
      "  {u'container': u'FCT', u'title': u'Clique-Width for Four-Vertex Forbidden Subgraphs.', u'author': [u'Andreas Brandstdt', u'Joost Engelfriet', u'Hong-Oanh Le', u'Vadim V. Lozin'], u'year': 2005, u'_id': ObjectId('5908979442e9c49335184591'), u'type': u'inproceedings', u'id': u'conf/fct/BrandstadtELL05'}\n",
      "\n",
      "  {u'container': u'SWEE', u'title': u'Home Page', u'author': [u'Joost Engelfriet'], u'year': 1995, u'_id': ObjectId('5908979842e9c493351ad884'), u'type': u'www', u'id': u'homepages/e/JoostEngelfriet'}\n",
      "\n",
      "  {u'container': u'Dependable Software Systems Engineering', u'title': u'Equivalence - Combinatorics, Algebra, Proofs.', u'author': [u'Helmut Seidl', u'Sebastian Maneth', u'Gregor Kemper', u'Joost Engelfriet'], u'year': 2016, u'_id': ObjectId('590897c442e9c4933534dd36'), u'type': u'incollection', u'id': u'series/natosec/SeidlMKE16'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author_to_search = \"Joost Engelfriet\"\n",
    "\n",
    "print(\"Publicaciones del autor %s :\\n\" %author_to_search.upper())\n",
    "for publication in publicaciones.find({\"author\": author_to_search}):\n",
    "    print('  %s\\n' %publication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo queremos el título del artículo y el año de publicación, podemos probar lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publicaciones del autor JOOST ENGELFRIET :\n",
      "\n",
      "1. Context-Free Graph Languages of Bounded Degree are Generated by Apex Graph Grammars. (1994)\n",
      "2. High Level Tree Transducers and Iterated Pushdown Tree Transducers. (1988)\n",
      "3. Extended multi bottom-up tree transducers. (2009)\n",
      "4. Context-Free Graph Grammars and Concatenation of Graphs. (1997)\n",
      "5. A new natural structural congruence in the pi-calculus with replication. (2004)\n",
      "6. Axioms for Generalized Graphs, Illustrated by a Cantor-Bernstein Proposition. (1998)\n",
      "7. Apex Graph Grammars and Attribute Grammars. (1988)\n",
      "8. The time complexity of typechecking tree-walking tree transducers. (2009)\n",
      "9. Branching Processes of Petri Nets. (1991)\n",
      "10. Extended Linear Macro Grammars, Iteration Grammars, and Register Programs. (1979)\n",
      "11. The Formal Power of One-Visit Attribute Grammars. (1981)\n",
      "12. Context-Free Hypergraph Grammars have the Same Term-Generating Power as Attribute Grammars. (1992)\n",
      "13. Two-way pebble transducers for partial functions and their composition. (2015)\n",
      "14. A comparison of pebble tree transducers with macro tree transducers. (2003)\n",
      "15. Attribute Storage Optimization by Stacks. (1990)\n",
      "16. Iterated Deterministic Substitution. (1977)\n",
      "17. The equivalence problem for deterministic MSO tree transducers is decidable. (2006)\n",
      "18. An Elementary Proof of Double Greibach Normal Form. (1992)\n",
      "19. A Kleene characterization of computability. (2007)\n",
      "20. On Tree Transducers for Partial Functions. (1978)\n",
      "21. Copying Theorems. (1976)\n",
      "22. An exercise in structural congruence. (2007)\n",
      "23. A Note on Infinite Trees. (1972)\n",
      "24. Prefix and Equality Languages of Rational Functions are Co-Context-Free. (1988)\n",
      "25. The complexity of the circularity problem for attribute grammars: a note on a counterexample for a simpler construction. (1989)\n",
      "26. Domino Treewidth. (1997)\n",
      "27. A Tranlsational Theorem for the Class of EOL Languages (1981)\n",
      "28. The Power to Two-Way Deterministic Checking Stack Automata (1989)\n",
      "29. Equality Languages and Fixed Point Languages (1979)\n",
      "30. Linear Graph Grammars: Power and Complexity (1989)\n",
      "31. Macro Tree Transducers, Attribute Grammars, and MSO Definable Tree Translations. (1999)\n",
      "32. Look-Ahead on Pushdowns (1987)\n",
      "33. Iterated Stack Automata and Complexity Classes (1991)\n",
      "34. The generative power of delegation networks. (2015)\n",
      "35. Decidability of the Finiteness of Ranges of Tree Transductions. (1998)\n",
      "36. Passes and Paths of Attributive Grammars (1981)\n",
      "37. Bounded Nesting in Macro Grammars (1979)\n",
      "38. A Comparison of Boundary Graph Grammars and Context-Free Hypergraph Grammars (1990)\n",
      "39. Derivation Trees of Ground Term Rewriting Systems. (1999)\n",
      "40. Stack Machines and Classes of Nonnested Macro Languages. (1980)\n",
      "41. Fixed Point Languages, Equality Languages, and Representation of Recursively Enumerable Languages. (1980)\n",
      "42. Passes, sweeps, and visits in attribute grammars. (1989)\n",
      "43. Three Hierarchies of Transducers. (1982)\n",
      "44. Composition Closure of Linear Extended Top-down Tree Transducers. (2017)\n",
      "45. Clique-Width for 4-Vertex Forbidden Subgraphs. (2006)\n",
      "46. Erratum to: \"Top-down Tree Transducers with Regular Look-ahead\". (2016)\n",
      "47. A Logical Characterization of the Sets of Hypergraphs Defined by Hyperedge Replacement Grammars. (1995)\n",
      "48. Bottom-up and Top-down Tree Transformations - A Comparison. (1975)\n",
      "49. Top-down Tree Transducers with Regular Look-ahead. (1977)\n",
      "50. Tree Transducers, L Systems, and Two-Way Machines. (1980)\n",
      "51. The Equivalence of Bottom-Up and Top-Down Tree-to-Graph Transducers. (1998)\n",
      "52. Deciding equivalence of top-down XML transformations in polynomial time. (2009)\n",
      "53. Handle-Rewriting Hypergraph Grammars. (1993)\n",
      "54. Macro Tree Transducers. (1985)\n",
      "55. Boundary Graph Grammars with Dynamic Edge Relabeling. (1990)\n",
      "56. IO and OI. II. (1978)\n",
      "57. Hypergraph Languages of Bounded Degree. (1994)\n",
      "58. Logical Description of Contex-Free Graph Languages. (1997)\n",
      "59. IO and OI. I. (1977)\n",
      "60. Determinacy and rewriting of functional top-down and MSO tree transformations. (2017)\n",
      "61. The Copying Power of One-State Tree Transducers. (1982)\n",
      "62. Regular Description of Context-Free Graph Languages. (1996)\n",
      "63. Hierarchies of Hyper-AFLs. (1985)\n",
      "64. Context Free Normal Systems and ETOL Systems. (1983)\n",
      "65. Branching synchronization grammars with nested tables. (2004)\n",
      "66. A Comparison of Tree Transductions Defined by Monadic Second Order Logic and by Attribute Grammars. (2000)\n",
      "67. Simple Multi-Visit Attribute Grammars. (1982)\n",
      "68. Extended Macro Grammars and Stack Controlled Machines. (1984)\n",
      "69. The Translation Power of Top-Down Tree-to-Graph Transducers. (1994)\n",
      "70. Output String Languages of Compositions of Deterministic Macro Tree Transducers. (2002)\n",
      "71. Finite Languages for the Representation of Finite Graphs. (1996)\n",
      "72. The Complexity of Regular DNLC Graph Languages. (1990)\n",
      "73. The String Generating Power of Context-Free Hypergraph Grammars. (1991)\n",
      "74. The non-computability of computability. (1985)\n",
      "75. Book: Graph Structure and Monadic Second-Order Logic. A Language-Theoretic Approach. (2012)\n",
      "76. Reverse Twin Shuffles. (1996)\n",
      "77. Context-Free Grammars with Storage. (2014)\n",
      "78. Look-Ahead Removal for Top-Down Tree Transducers. (2013)\n",
      "79. The Equivalence Problem for Deterministic MSO Tree Transducers is Decidable (2005)\n",
      "80. Tree Automata and Tree Grammars. (2015)\n",
      "81. MSO definable string transductions and two-way finite state transducers (1999)\n",
      "82. Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure (2007)\n",
      "83. Complexity of boundary graph languages. (1990)\n",
      "84. MSO definable string transductions and two-way finite-state transducers. (2001)\n",
      "85. Bottom-Up and Top-Down Tree Series Transformations. (2002)\n",
      "86. Finitary Compositions of Two-way Finite-State Transductions. (2007)\n",
      "87. Grammatical Codes of Trees and Terminally Coded Grammars. (1995)\n",
      "88. Modular Tree Transducers. (1991)\n",
      "89. Nonterminal Separation in Graph Grammars. (1991)\n",
      "90. As Time Goes By II: More Automatic Complexity Analysis of Concurrent Rule Programs. (2001)\n",
      "91. Characterization and Complexity of Uniformly Non Primitive Labeled 2-Structures. (1996)\n",
      "92. X-Automata on omega-Words. (1993)\n",
      "93. A Regular Characterization of Graph Languages Definable in Monadic Second-Order Logic. (1991)\n",
      "94. Determinacy - (Observation Equivalence = Trace Equivalence). (1985)\n",
      "95. Pushdown Machines for the Macro Tree Transducer. (1986)\n",
      "96. Look-ahead removal for total deterministic top-down tree transducers. (2016)\n",
      "97. Surface Tree Languages and Parallel Derivation Trees. (1976)\n",
      "98. Structural inclusion in the pi-calculus with replication. (2001)\n",
      "99. Nonterminal Bounded NLC Graph Grammars. (1988)\n",
      "100. Multisets and Structural Congruence of the pi-Calculus with Replication. (1999)\n",
      "101. Iterating Iterated Substitution. (1977)\n",
      "102. A Multiset Semantics for the pi-Calculus with Replication. (1996)\n",
      "103. Trips on Trees. (1999)\n",
      "104. Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure. (2007)\n",
      "105. The complexity of Languages Generated by Attribute Grammars. (1986)\n",
      "106. Macro Tree Translations of Linear Size Increase are MSO Definable. (2003)\n",
      "107. Graph Structure and Monadic Second-Order Logic - A Language-Theoretic Approach. (2012)\n",
      "108. Simple Program Schemes and Formal Languages (1974)\n",
      "109. The Delta Operation: From Strings to Trees to Strings. (2002)\n",
      "110. Tree-Walking Pebble Automata. (1999)\n",
      "111. Monadic Second Order Logic and Node Relations on Graphs and Trees. (1997)\n",
      "112. Deciding the NTS Property of Context-Free Grammars. (1994)\n",
      "113. Strong Lexicalization of Tree Adjoining Grammars. (2012)\n",
      "114. Domino Treewith (Extended Abstract). (1994)\n",
      "115. A Multiset Semantics for the pi-Calculus with Replication. (1993)\n",
      "116. Regular Characterizations of Macro Tree Transducers. (1984)\n",
      "117. Graph Grammars and Tree Transducers. (1994)\n",
      "118. Elementary Net Systems. (1996)\n",
      "119. Attribute Grammars: Attribute Evaluation Methods. (1983)\n",
      "120. Net-Based Description Of Parallel Object-Based Systems, or POTs and POPs. (1990)\n",
      "121. Nested Pebbles and Transitive Closure. (2006)\n",
      "122. Characterizing and Deciding MSO-Definability of Macro Tree Transductions. (2000)\n",
      "123. Restricting the complexity of regular DNLC languages. (1986)\n",
      "124. Context-free Handle-rewriting Hypergraph Grammars. (1990)\n",
      "125. Node Replacement Graph Grammars. (1997)\n",
      "126. A Characterization of Context-Free NCE Graph Languages by Monadic Second-Order Logic on Trees. (1990)\n",
      "127. The Term Generating Power of Context-Free Hypergraph Grammars. (1990)\n",
      "128. Graph Grammars Based on Node Rewriting: An Introduction to NLC Graph Grammars. (1990)\n",
      "129. Apex Graph Grammars. (1986)\n",
      "130. XML transformation by tree-walking transducers with invisible pebbles. (2007)\n",
      "131. Iterated Pushdown Automata and Complexity Classes (1983)\n",
      "132. Tree Transducers, L Systems and Two-Way Machines (Extended Abstract) (1978)\n",
      "133. Characterization of High Level Tree Transducers. (1985)\n",
      "134. A Greibach Normal Form for Context-free Graph Grammars. (1992)\n",
      "135. Two-Way Finite State Transducers and Monadic Second-Order Logic. (1999)\n",
      "136. Passes, Sweeps and Visits. (1981)\n",
      "137. Formal Properties of One-Visit and Multi-Pass Attribute Grammars. (1980)\n",
      "138. Automata with Storage on Infinite Words. (1989)\n",
      "139. Translation of Simple Program Schemes. (1972)\n",
      "140. Macro Grammars, Lindenmayer Systems and Other Copying Devices. (1977)\n",
      "141. Tree Languages Generated be Context-Free Graph Grammars. (1998)\n",
      "142. Concatenation of Graphs. (1994)\n",
      "143. Equality Languages, Fixed Point Languages and Representations of Recursively Enumerable Languages (1978)\n",
      "144. Two-Way Finite State Transducers with Nested Pebbles. (2002)\n",
      "145. Determinacy and Rewriting of Top-Down and MSO Tree Transformations. (2013)\n",
      "146. The Equivalence Problem for Deterministic MSO Tree Transducers Is Decidable. (2005)\n",
      "147. Branching Grammars: A Generalization of ET0L Systems. (2003)\n",
      "148. Hierarchies of String Languages Generated by Deterministic Tree Transducers. (2001)\n",
      "149. Extended Multi Bottom-Up Tree Transducers. (2008)\n",
      "150. How to Remove the Look-Ahead of Top-Down Tree Transducers. (2014)\n",
      "151. Context-Free NCE Graph Grammars. (1989)\n",
      "152. Clique-Width for Four-Vertex Forbidden Subgraphs. (2005)\n",
      "153. Home Page (1995)\n",
      "154. Equivalence - Combinatorics, Algebra, Proofs. (2016)\n"
     ]
    }
   ],
   "source": [
    "print(\"Publicaciones del autor %s :\\n\" %author_to_search.upper())\n",
    "query = publicaciones.find({\"author\": author_to_search})\n",
    "for i, publication in enumerate(query):\n",
    "    print('%d. %s (%d)' %(i+1, \n",
    "                          publication[u'title'], \n",
    "                          publication[u'year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**2. Número de publicaciones de un autor determinado**.\n",
    "\n",
    "La siguiente consulta devuelve el número de publicaciones dado un autor. Para poder efectuarla, el nombre del autor se pasa a través de la variable `author_to_search`.\n",
    "\n",
    "*Para esta pregunta, el índice utilizado es `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 publicaciones hechas por Joost Engelfriet\n"
     ]
    }
   ],
   "source": [
    "author_to_search = \"Joost Engelfriet\"\n",
    "pubs_c = publicaciones.find({\"author\": author_to_search}).count()\n",
    "print(str(pubs_c) + \" publicaciones hechas por \" + author_to_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** 3. Número de artículos en revista para el año 2016. **\n",
    "\n",
    "El siguiente bloque de código incluye las sentencias necesarias para responder a la pregunta. Para poder efectuarla, el año y el tipo de documento se pasan a través de las variables `year` y `document_type` respectivamente.\n",
    "\n",
    "*Para esta pregunta, los índices utilizados son `year` y `type`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de artículos en revista publicados en 2016: 126954\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2016\n",
    "document_type = \"article\" # los artículos en revista son de este tipo\n",
    "\n",
    "query = {\"$and\":[{\"year\": YEAR}, {\"type\": document_type}]}\n",
    "publications_count = publicaciones.find(query).count()\n",
    "\n",
    "print(\"Número de artículos en revista publicados en %d: %d\" \n",
    "      %(YEAR, publications_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**4. Número de autores ocasionales, es decir, que tengan menos de 5 publicaciones en total**.\n",
    "\n",
    "El siguiente código da como resultado el número de autores con menos de 5 publicaciones. El número mínimo se pasa a través de la variable `min_pubs`.\n",
    "\n",
    "*Para este pregunta, el índice utilizado es `author`*\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 1399949 autores con menos de 5 publicaciones\n"
     ]
    }
   ],
   "source": [
    "min_pubs = 5\n",
    "pl = [{\"$unwind\": \"$author\"},\n",
    "      {\"$sortByCount\": \"$author\"},\n",
    "      {\"$match\": {'count':{\"$lt\": min_pubs}}},\n",
    "      {\"$group\": {'_id': 'null', 'count': { \"$sum\": 1 } } }]\n",
    "count = list(publicaciones.aggregate(pl, allowDiskUse=True))[0][u'count']\n",
    "print(\"Hay %d autores con menos de %d publicaciones\" %(count, min_pubs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos obtener el listado de todos los autores (no recomendado, por el tiempo de ejecución), se puede probar el siguiente código:\n",
    "```python\n",
    "min_pubs = 5\n",
    "pl = [{\"$unwind\": \"$author\"},\n",
    "            {\"$sortByCount\": \"$author\"},\n",
    "            {\"$match\": {'count':{\"$lt\": min_pubs}}}]\n",
    "for au in publicaciones.aggregate(pl, allowDiskUse=True):\n",
    "    print (\"El autor %s tiene %d publicaciones.\" \n",
    "            %(str(au['_id']), au['count']))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** 5. Número de artículos de revista (`article`) y número de artículos en congresos\n",
    "(`inproceedings`) de los diez autores con más publicaciones totales. **\n",
    "\n",
    "A continuación se incluye el código que proporciona la información requerida.\n",
    "\n",
    "*Para esta pregunta, el índice utilizado es `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wen Gao 0001 ha publicado 0 veces en revistas e intervenido 715 veces en congresos (total: 715)\n",
      "Philip S. Yu ha publicado 0 veces en revistas e intervenido 652 veces en congresos (total: 652)\n",
      "Wei Zhang ha publicado 0 veces en revistas e intervenido 650 veces en congresos (total: 650)\n",
      "Thomas S. Huang ha publicado 0 veces en revistas e intervenido 607 veces en congresos (total: 607)\n",
      "Hai Jin ha publicado 0 veces en revistas e intervenido 570 veces en congresos (total: 570)\n",
      "Yang Liu ha publicado 0 veces en revistas e intervenido 565 veces en congresos (total: 565)\n",
      "Yu Zhang ha publicado 0 veces en revistas e intervenido 556 veces en congresos (total: 556)\n",
      "Jiawei Han ha publicado 0 veces en revistas e intervenido 549 veces en congresos (total: 549)\n",
      "Jing Li ha publicado 0 veces en revistas e intervenido 543 veces en congresos (total: 543)\n",
      "Makoto Takizawa ha publicado 0 veces en revistas e intervenido 543 veces en congresos (total: 543)\n"
     ]
    }
   ],
   "source": [
    "from bson.son import SON\n",
    "\n",
    "pl = [{\"$unwind\":\"$author\"},\n",
    "      {\"$group\":{\"_id\":\"$author\",\n",
    "                 \"art_congreso\":\n",
    "                 {\"$push\":{\"$cond\":[{\"$eq\":[\"$type\",\"inproceedings\"]}, 1, 0]}},\n",
    "                 \"type\":{\"$push\":\"$type\"}\n",
    "                }\n",
    "      },\n",
    "      {\"$addFields\":{\"art_revista\":{\"$sum\":\"$art_revista\"},\n",
    "                     \"art_congreso\":{\"$sum\":\"$art_congreso\"}}\n",
    "      },\n",
    "      {\"$addFields\":{\"art_totales\": \n",
    "                     {\"$add\":[\"$art_revista\", \"$art_congreso\"]}}\n",
    "      },\n",
    "      {\"$sort\":{\"art_totales\":-1}},\n",
    "      {\"$project\":{\"art_totales\":1, \"_id\":1, \n",
    "                   \"art_revista\":1, \"art_congreso\":1}\n",
    "      },\n",
    "      {\"$limit\":10}\n",
    "     ]\n",
    "\n",
    "for individual_publi_data in publicaciones.aggregate(pl, allowDiskUse=True):\n",
    "    print (\n",
    "        '%s ha publicado %d veces en revistas e intervenido \\\n",
    "%d veces en congresos (total: %d)' \n",
    "           %(individual_publi_data['_id'],\n",
    "             individual_publi_data['art_revista'],\n",
    "             individual_publi_data['art_congreso'],\n",
    "             individual_publi_data['art_totales']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**6. Número medio de autores de todas las publicaciones que tenga en su conjunto de datos.**\n",
    "\n",
    "En este apartado se han implementado dos tipos de consultas. La primera extrae la media de autores por tipo de publicación. La segunda devuelve como resultado el número medio de autores teniendo en cuenta todas las publicaciones de la base de datos.\n",
    "\n",
    "*Para estas consultas, el índice utilizado es `type`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad media de autores para el tipo de publicación 'proceedings' es de 3.11\n",
      "La cantidad media de autores para el tipo de publicación 'inproceedings' es de 3.04\n",
      "La cantidad media de autores para el tipo de publicación 'article' es de 2.77\n",
      "La cantidad media de autores para el tipo de publicación 'incollection' es de 2.19\n",
      "La cantidad media de autores para el tipo de publicación 'book' es de 1.65\n",
      "La cantidad media de autores para el tipo de publicación 'www' es de 1.02\n",
      "La cantidad media de autores para el tipo de publicación 'phdthesis' es de 1.00\n",
      "La cantidad media de autores para el tipo de publicación 'mastersthesis' es de 1.00\n",
      "\n",
      "La media de autores es de 1.75\n"
     ]
    }
   ],
   "source": [
    "pl = [{\"$group\":\n",
    "       {\"_id\":\"$type\",\n",
    "        \"authorMean\":{\"$avg\":{\"$size\":{ \"$ifNull\": [ \"$author\", [] ] }}}\n",
    "       }\n",
    "      }]\n",
    "au_mean_pars = [x for x in publicaciones.aggregate(pl) if x['authorMean'] != 0.0]\n",
    "sorted_au_mean_pars = sorted(au_mean_pars, \n",
    "                             key=lambda k: k['authorMean'], \n",
    "                             reverse=True) \n",
    "for au_mean_par in sorted_au_mean_pars:\n",
    "    print(\"La cantidad media de autores para el \\\n",
    "tipo de publicación '%s' es de %.2f\"\n",
    "          %(str(au_mean_par['_id']), au_mean_par['authorMean']))\n",
    "\n",
    "pl = [{\"$group\":\n",
    "       {\"_id\":\"$type\",\n",
    "        \"auMean_perPub\":{\"$avg\":{\"$size\":{ \"$ifNull\": [ \"$author\", [] ] }}}}},\n",
    "      {\"$group\":{\"_id\":\"null\",\"authorMean_tot\":{\"$avg\":\"$auMean_perPub\"}}}\n",
    "     ]\n",
    "for au_mean_tot in publicaciones.aggregate(pl):\n",
    "     print(\"\\nLa media de autores es de %.2f\" %au_mean_tot['authorMean_tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** 7. Listado de coautores de un autor (Se denomina coautor a cualquier persona que haya firmado una publicación). **\n",
    "\n",
    "A continuación se incluye el código necesario para responder a la pregunga. El nombre del autor objeto de la consulta se pasa en la variable `author_to_search`. Sigue siendo nuestro amigo *Joost Engelfriet*.\n",
    "\n",
    "*Para esta pregunta, el índice utilizado es `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de coautores del autor Joost Engelfriet:\n",
      "1. Vincent van Oostrom\n",
      "2. Bart Samwel\n",
      "3. Linda Heyker\n",
      "4. Giora Slutzki\n",
      "5. Andreas Maletti\n",
      "6. Jan Joris Vereijken\n",
      "7. Frank Drewes\n",
      "8. Tjalling Gelsema\n",
      "9. Hong-Oanh Le\n",
      "10. Erik Meineche Schmidt\n",
      "11. Emo Welzl\n",
      "12. Thom W. Frhwirth\n",
      "13. Tero Harju\n",
      "14. Vadim V. Lozin\n",
      "15. Andrzej Ehrenfeucht\n",
      "16. Paulien ten Pas\n",
      "17. Eric Lilin\n",
      "18. Michael Benedikt\n",
      "19. Gilberto Fil\n",
      "20. George Leih\n",
      "21. Heiko Vogler\n",
      "22. Sven Skyum\n",
      "23. Hendrik Jan Hoogeboom\n",
      "24. Mirko Krivnek\n",
      "25. Jaroslav Morvek\n",
      "26. Jan van Leeuwen\n",
      "27. Grzegorz Rozenberg\n",
      "28. Willem de Jong\n",
      "29. Hans L. Bodlaender\n",
      "30. Bruno Courcelle\n",
      "31. Jan-Pascal van Best\n",
      "32. IJsbrand Jan Aalbersberg\n",
      "33. Peter R. J. Asveld\n",
      "34. Roderick Bloem\n",
      "35. Gregor Kemper\n",
      "36. Andrzej Proskurowski\n",
      "37. Sebastian Maneth\n",
      "38. Zoltn Flp 0001\n",
      "39. Andreas Brandstdt\n",
      "40. Helmut Seidl\n"
     ]
    }
   ],
   "source": [
    "target = \"Joost Engelfriet\"\n",
    "\n",
    "author_publications = publicaciones.find({\"author\":target})\n",
    "authors_list = [publication['author'] for publication in author_publications]\n",
    "coauthors_list = \\\n",
    "    set(\n",
    "        [item for sublist in authors_list for item in sublist if item!=target]\n",
    "    )\n",
    "\n",
    "print(\"Lista de coautores del autor %s:\" %author_to_search)\n",
    "for i, author in enumerate(coauthors_list):\n",
    "    print ('%d. %s' %(i+1, author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**8. Edad de los cinco autores con un periodo de publicaciones más largo (se considera la edad de un autor al número de  años transcurridos desde la fecha de su primera publicación hasta la última registrada).**\n",
    "\n",
    "El número de autores que queremos obtener se pasa en la variable `num_auth`.\n",
    "\n",
    "*Para esta pregunta, el índice utilizado es `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La edad de Alan M. Turing es de 75 años\n",
      "La edad de Rudolf Carnap es de 71 años\n",
      "La edad de David Nelson es de 67 años\n",
      "La edad de Eric Weiss es de 64 años\n",
      "La edad de Claude E. Shannon es de 63 años\n"
     ]
    }
   ],
   "source": [
    "num_auth = 5\n",
    "\n",
    "pl = [{\"$unwind\":\"$author\"},\n",
    "      {\"$group\":\n",
    "           {\"_id\":\"$author\",\n",
    "            \"minYear\":{\"$min\":\"$year\"},\n",
    "            \"maxYear\":{\"$max\":\"$year\"}}},\n",
    "      {\"$addFields\":{\"edad\":{\"$subtract\":[\"$maxYear\",\"$minYear\"]}}},\n",
    "      {\"$sort\":{\"edad\":-1}},\n",
    "      {\"$limit\": num_auth}\n",
    "     ]\n",
    "\n",
    "for aut_age in publicaciones.aggregate(pl, allowDiskUse=True):\n",
    "     print(\"La edad de %s es de %d años\" \n",
    "           %(str(aut_age['_id']), aut_age[\"edad\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** 9. Número de autores novatos, es decir, que tengan una edad menor de cinco años (Se considera la edad de un autor al número de años transcurridos desde la fecha de su primera publicación hasta la última registrada). **\n",
    "\n",
    "La edad máxima se pasa en la variable `edad`.\n",
    "\n",
    "*Índice utilizado para esta pregunta: `author`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de autores con una edad menor de 5 años: 114067\n"
     ]
    }
   ],
   "source": [
    "edad = 5\n",
    "\n",
    "pl = [{\"$unwind\":\"$author\"},\n",
    "      {\"$group\":{\"_id\":\"$author\",\n",
    "                 \"year\":{\"$push\":\"$year\"}}},\n",
    "      {\"$addFields\":{\"max_year\":{\"$max\":\"$year\"},\n",
    "                     \"min_year\":{\"$min\":\"$year\"}}},\n",
    "      {\"$addFields\":{\"edad\":{\"$subtract\":[\"$max_year\", \"$min_year\"]}}},\n",
    "      {\"$project\":{\"_id\":0,\"autor\":\"$_id\",\"edad\":1}},\n",
    "      {\"$match\":{\"edad\":{\"$lt\":edad}}},\n",
    "      {\"$sort\":{\"edad\":-1}},\n",
    "      {\"$count\":\"número_autores\"}\n",
    "     ]\n",
    "\n",
    "data = [i for i in publicaciones.aggregate(pl, allowDiskUse=True)]\n",
    "\n",
    "print(\"Número de autores con una edad menor de %d años: %d\" \n",
    "      %(edad, data[0][u'número_autores']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**10. Porcentaje de publicaciones en revistas con respecto al total de publicaciones.**\n",
    "\n",
    "En este apartado se obteniene el porcentaje de artículos publicados en revistas respecto al total de publicaciones. El tipo de publicación se pasa en la variable `type` (`article`).\n",
    "\n",
    "*El índice utilizado es `type`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un 28.82% de publicaciones de tipo article respecto al total de publicaciones\n"
     ]
    }
   ],
   "source": [
    "type = 'article'\n",
    "total_docs = publicaciones.find().count()\n",
    "\n",
    "pl = [{\"$group\":{\"_id\":\"$type\",\"count\":{\"$sum\":1}}},\n",
    "      {\"$project\":{\"count\":1,\"per\":\n",
    "                   {\"$multiply\":[{\"$divide\":[100,total_docs]},\"$count\"]}\n",
    "                  }},\n",
    "      {\"$match\": {'_id': type}}\n",
    "     ]\n",
    "\n",
    "data = [i for i in publicaciones.aggregate(pl)]\n",
    "\n",
    "if len(data) > 0 :\n",
    "    print(\n",
    "        \"Hay un %.2f%% de publicaciones de tipo %s \\\n",
    "respecto al total de publicaciones\"\n",
    "        %(data[0][u'per'], type))\n",
    "else :\n",
    "    print(\"No hay publicaciones de tipo '%s'\" %(type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte II: Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1) Captura y procesamiento de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "El procedimiento adoptado en este caso será similar al relativo a MongoDB. La única diferencia será que, en vez de crearse ficheros JSON, se trabajará con ficheros CSV. A priori, existen dos estrategias diferentes:\n",
    "\n",
    "* volver a procesar el fichero XML para generar el o los ficheros CSV que luego serán importados desde Neo4j. Una estrategia similar consistiría en hacer un procesado parecido pero desde los ficheros JSON obtenidos en el primer procesado. El uso de JSON en lugar de XML simplificaría notablemente el proceso.\n",
    "* utilizar el contenido de MongoDB, exportando uno o varios ficheros CSV con los datos necesarios para poder ser cargados posteriormente en Neo4j. Para ello, es posible que haya que generar alguna colección adicional.\n",
    "\n",
    "En cualquier caso, es necesario determinar cuál será el modelo de datos que utilizaremos. Tratándose de una base de datos orientada a grafos parece evidente considerar los siguientes nodos: `Publication` y `Author`. Y una relación, `HAS_PUBLISHED`. Aunque tenemos también la información sobre el medio en el que se han publicado, lo que habilitaría un modelado en el que hubiese dos nodos (`Author` y `Container`), con `Publication` como arista, hemos preferido un enfoque más simple.\n",
    "\n",
    "A efectos ilustrativos proporcionamos un ejemplo de un registro extraido de los ficheros JSON y una sentencia en lenguaje Cypher que permitiría crear los nodos y aristas correspondientes:\n",
    "\n",
    "```json\n",
    "{\"author\": [\"Sanjeev Saxena\"], \"container\": \"Acta Inf.\", \n",
    "\"id\": \"journals/acta/Saxena96\", \n",
    "\"title\": \"Parallel Integer Sorting and Simulation Amongst CRCW Models.\", \n",
    "\"type\": \"article\", \"year\": 1996}\n",
    "```\n",
    "Una propuesta de sentencia Cypher sería la siguiente:\n",
    "\n",
    "```sql\n",
    "CREATE (journals_acta_Saxena96:Publication \n",
    "    {container: \"Acta Inf.\", \n",
    "    title: \"Parallel Integer Sorting and Simulation Amongst CRCW Models\", \n",
    "    type: \"article\"}\n",
    ")\n",
    "CREATE (Sanjeev_Saxena:Author {name: 'Sanjeev Saxena'})\n",
    "CREATE (Sanjeev_Saxena)-[:HAS_PUBLISHED {year:1996}]-> (journals_acta_Saxena96)\n",
    "```\n",
    "\n",
    "Puede observarse que sugerimos la utilización como nombre de los nodos del tipo `Publication` el `id` único de la publicación, sustituyendo las barras por guiones bajos. El nombre de los nodos de tipo `Author` será el nombre del autor sustituyendo los espacios por guiones bajos (todo ello debido a que no es posible incluir espacios dentro de los nombres de los nodos o aristas de Neo4j).\n",
    "\n",
    "El reto ahora se encuentra en preparar los datos para que puedan ser importados desde Neo4j.\n",
    "\n",
    "Comenzamos por los autores. El fichero CSV con los datos de los autores puede prepararse a partir de una consulta de MongoDB que cree una colección (`authors`) con los autores únicos presentes en la base de datos (suponiendo que nos hemos conectado a la base de datos `documentos`):\n",
    "```sql\n",
    "db.publicaciones.aggregate(\n",
    "[\n",
    "    {$unwind : \"$author\" },\n",
    "    {$group : {_id : \"$author\", \"name\" : { $first: \"$author\" }}},\n",
    "    {$out: \"authors\"}\n",
    "],\n",
    "{\n",
    "    allowDiskUse:true\n",
    "})\n",
    "```\n",
    "Verificamos la creación correcta de la colección averiguando el número de autores:\n",
    "```sql\n",
    "db.authors.count()\n",
    "```\n",
    "Se trata de 1899746 autores.\n",
    "\n",
    "Para crear un fichero CSV con los datos de las publicaciones, ejecutaremos la siguiente orden, con lo que obtendremos la colección `publications`:\n",
    "```sql\n",
    "db.publicaciones.aggregate( [\n",
    "    {$project:{_id: 0, \"container\":1, \n",
    "        \"publication_id\":\"$id\", \n",
    "        \"title\":1, \"type\":1, \n",
    "        \"year\":1}},\n",
    "    {$out: \"publications\"}\n",
    "] )\n",
    "```\n",
    "Verificamos el número de publicaciones:\n",
    "```sql\n",
    "db.publications.count()\n",
    "```\n",
    "Como esperábamos, obtenemos 5507168 publicaciones.\n",
    "\n",
    "Finalmente creamos un fichero CSV con las relaciones entre autores y publicaciones. Para ello ejecutamos la siguiente orden, con la que obtendremos la colección `relationships`:\n",
    "```sql\n",
    "db.publicaciones.aggregate( [\n",
    "    {$unwind : \"$author\" },\n",
    "    {$project:{_id: 0, \"name\":\"$author\", \"publication_id\":\"$id\"}},\n",
    "    {$out: \"relationships\"}\n",
    "])\n",
    "```\n",
    "En este caso, obtenemos 12335676 relaciones.\n",
    "\n",
    "Una vez que tenemos las nuevas colecciones creadas, hemos abordado la creación de los ficheros CSV utilizando `mongoexport`, de la siguiente forma:\n",
    "\n",
    "```bash\n",
    "mongoexport -d publicaciones -c authors \\\n",
    "    --type=csv --fields name --out authors.csv\n",
    "mongoexport -d publicaciones -c publications \\\n",
    "    --type=csv --fields container,publication_id,title,type,year \\\n",
    "    --out publications.csv\n",
    "mongoexport -d publicaciones -c relationships \\\n",
    "    --type=csv --fields name,publication_id \\\n",
    "    --out relationships.csv\n",
    "```\n",
    "Sin embargo, hemos comprobado que el resultado no es demasiado bueno. El problema fundamental es que `mongoexport` no permite la personalización del carácter de separación, ya que la coma es el carácter utilizado por defecto. Este carácter colisiona con el uso de comas, por ejemplo, en el título de los artículos, con lo que a la hora de importar los ficheros, aparecía un número variable, y erróneo de campos en cada registro. Por ello, finalmente hemos tenido que utilizar otro enfoque, basado en Python, de forma que pudiéramos, por una parte, utilizar el tabulador como carácter de separación y, por otra parte, controlásemos el uso de comillas.\n",
    "\n",
    "Un esquema del *script* utilizado, `export_db.py`, lo mostramos a continuación:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import codecs\n",
    "from pymongo import MongoClient\n",
    "import sys\n",
    "\n",
    "print(\"Dumping authors.csv\")\n",
    "file = codecs.open(\"authors.csv\", \"w\", \"utf-8\")\n",
    "# CSV header for 'Author' label\n",
    "file.write (\":ID\\tname\\n\")\n",
    "conex = MongoClient('localhost', 27017)\n",
    "db = conex.docos\n",
    "authors = db['authors']\n",
    "cursor = authors.find({})\n",
    "for doc in cursor:\n",
    "    if \"'\" in doc['name'] :\n",
    "        file.write('\"' + doc['_id'] + '\"\\t\"' + doc['name'] + '\"\\n')\n",
    "    else :\n",
    "        file.write(doc['_id'] + '\\t' + doc['name']+ '\\n')\n",
    "\n",
    "file.close()\n",
    "print(\"\\nDumped authors.csv\\n\")\n",
    "\n",
    "print(\"Dumping publications.csv\")\n",
    "file = codecs.open(\"publications.csv\", \"w\", \"utf-8\")\n",
    "# CSV header for 'Publication' label\n",
    "file.write(\":ID\\tcontainer\\ttitle\\ttype\\tyear\\n\")\n",
    "conex = MongoClient('localhost', 27017)\n",
    "db = conex.docos\n",
    "publications = db['publications']\n",
    "cursor = publications.find({})\n",
    "discards = []\n",
    "for doc in cursor:\n",
    "    try:\n",
    "        if \"'\" in doc['title']:\n",
    "            file.write(doc['publication_id'] + '\\t' +\n",
    "                       doc['container'].replace(\"'\", \"\").replace('\"', '') +\n",
    "                       '\\t\"' + doc['title'].replace('\"', '') + '\"\\t' +\n",
    "                       doc['type'] + '\\t' +\n",
    "                       str(doc['year']) + '\\n')\n",
    "        else:\n",
    "            file.write(doc['publication_id'] + '\\t' +\n",
    "                       doc['container'].replace(\"'\", \"\").replace('\"', '') +\n",
    "                       '\\t' +  doc['title'].replace('\"', '') + '\\t' +\n",
    "                       doc['type'] + '\\t' +\n",
    "                       str(doc['year']) + '\\n')\n",
    "    except Exception as e:\n",
    "        if 'publication_id' in doc:\n",
    "            discards.append(doc['publication_id'])\n",
    "\n",
    "file.close()\n",
    "print(\"\\nDumped publications.csv\\n\")\n",
    "\n",
    "print(\"Dumping relationships.csv\")\n",
    "file = codecs.open(\"relationships.csv\", \"w\", \"utf-8\")\n",
    "# CSV header for 'HAS_PUBLISHED' label\n",
    "file.write (\":START_ID\\t:END_ID\\n\")\n",
    "conex = MongoClient('localhost', 27017)\n",
    "db = conex.docos\n",
    "relationships = db['relationships']\n",
    "cursor = relationships.find({})\n",
    "for doc in cursor:\n",
    "    if doc['publication_id'] not in discards:\n",
    "        if \"'\" in doc['name'] :\n",
    "            file.write('\"' + doc['name'] + '\"\\t' +\n",
    "                       doc['publication_id'] + '\\n')\n",
    "        else :\n",
    "            file.write(doc['name'] + '\\t' +\n",
    "                       doc['publication_id']+ '\\n')\n",
    "\n",
    "file.close()\n",
    "print(\"\\nDumped relationships.csv\")\n",
    "\n",
    "```\n",
    "El resultado serán tres ficheros CSV con los contenidos de los autores, las publicaciones y las relaciones respectivamente. Los hemos subido a AWS S3, donde se encuentran en las siguientes URL: <https://s3-eu-west-1.amazonaws.com/urjc.datascience.bdnc/authors.csv>, <https://s3-eu-west-1.amazonaws.com/urjc.datascience.bdnc/publications.csv> y <https://s3-eu-west-1.amazonaws.com/urjc.datascience.bdnc/relationships.csv>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2) Almacenamiento de datos \n",
    "\n",
    "La carga de los datos anteriores en Neo4J ha sido, sin duda, el aspecto más complicado de la presente práctica. Hemos hecho infinidad de pruebas que se han traducido en tiempos de carga inasumibles. Hemos probado a utilizar las funcionalidades de `LOAD CSV` desde el Neo4J browser, o a cargarlos con Python mediante la librería `py2neo`, utilizando enfoques mono y multiprocesos. Finalmente, el enfoque adecuado (y extremadamente rápido) ha sido el basado en la herramienta `neo4j-import` <https://neo4j.com/developer/guide-import-csv/#_super_fast_batch_importer_for_huge_datasets>.\n",
    "\n",
    "Si se ha prestado atención al código presentado en la sección anterior, se podrá observar el formato de las cabeceras de cada uno de los ficheros CSV:\n",
    "1. Para los autores:\n",
    "```\n",
    ":ID\t\tname\n",
    "```\n",
    "2. Para las publicaciones:\n",
    "```\n",
    ":ID\t\tcontainer\ttitle\ttype\tyear\n",
    "```\n",
    "3. Para las aristas entre autores y publicaciones:\n",
    "```\n",
    ":START_ID\t:END_ID\n",
    "```\n",
    "Los nombres de campo `:ID`, `:START_ID` y `:END_ID` son los que determinan cuáles son los comienzos y finales de las aristas y cuáles son los identificadores de cada nodo. Una vez fijados los campos, se ejecuta `neo4j-import`:\n",
    "\n",
    "```bash\n",
    "sudo /usr/bin/neo4j-import --into /var/lib/neo4j/data/databases/dblp.db \\\n",
    "--id-type string \\\n",
    "--nodes:Author authors.csv --nodes:Publication publications.csv \\\n",
    "--relationships:HAS_PUBLISHED relationships.csv \\\n",
    "--quote '\"' --delimiter \"TAB\"\n",
    "```\n",
    "\n",
    "En donde pueden verse las etiquetas (`label`) de nodos y aristas, la localización de la base de datos y los ficheros CSV de partida.\n",
    "\n",
    "A continuación hay que hacer activa la nueva base de datos (`/var/lib/neo4j/data/databases/dblp.db`), para lo que se fija la siguiente opción (`dbms.active_database=dblp.db`) en la configuración de Nej4J (`sudo nano /etc/neo4j/neo4j.conf`). A continuación se reinicia la base de datos:\n",
    "\n",
    "```bash\n",
    "sudo neo4j restart\n",
    "```\n",
    "El resultado ha sido muy satisfactorio:\n",
    "```\n",
    "IMPORT DONE in 1m 39s 79ms. \n",
    "Imported:\n",
    "  7389030 nodes\n",
    "  12335676 relationships\n",
    "  23856873 properties\n",
    "Peak memory usage: 195.93 MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3) Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el grafo está cargado, se pueden realizar diferentes consultas. Las primeras van a tener el objetivo fundamental de comprobar que la carga de los datos y la posterior construcción del grafo ha sido correcta, mientras que la últimas van a ser consultas que presentan grandes ventajas al ser realizadas en una base orientada a grafos en comparación con otro tipo de bases de datos como MongoDB. Mostraremos, por una parte, los resultados obtenidos a través del Neo4J Browser y, por otra, los obtenidos programáticamente, a través del paquete `py2neo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "graph = Graph(\"http://localhost:7474/db/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se va a comprobar el número de publicaciones, que en teoría ha de ser 5.507.168 (obtenidas en la sección relativa a MongoDB);\n",
    "\n",
    "* Consulta 1: Número de publicaciones\n",
    "\n",
    "```\n",
    "MATCH (n:Publication) \n",
    "RETURN count(n)\n",
    "```\n",
    "Obtenemos un total de 5.489.284 publicaciones. Es decir, varios miles menos de las esperadas. La razón es que el proceso de carga ha omitido aquellas publicaciones cuyo título poseía caracteres no Latin-1, que proporcionaban problemas de carga. Esto no sería aceptable en un entorno de producción, pero lo hemos considerado aceptable dentro de un entorno de pruebas y aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5489284"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = graph.data(\"MATCH (n:Publication) RETURN count(n)\")\n",
    "data[0][\"count(n)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora comprobamos el número de autores totales\n",
    "\n",
    "* Consulta 2: Número de autores\n",
    "\n",
    "```\n",
    "MATCH (n:Author) \n",
    "RETURN count(n)\n",
    "```\n",
    "\n",
    "Obtenemos un total de 189.9746 autores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899746"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = graph.data(\"MATCH (n:Author) RETURN count(n)\")\n",
    "data[0][\"count(n)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 3: Publicaciones de nuestro viejo amigo, el autor \"Joost Engelfriet\"\n",
    "Utilizamos tres enfoques diferentes:\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE author.name = \"Joost Engelfriet\"\n",
    "RETURN (author)-[:HAS_PUBLISHED]->(pub)\n",
    "```\n",
    "Resultado: un grafo donde el autor \"Joost Engelfriet\" está unido a 154 publicaciones, como ya comprobamos en MongoDB. Véase el grafo:\n",
    "<img src=\"graph.png\">\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE author.name = \"Joost Engelfriet\"\n",
    "RETURN pub.title\n",
    "```\n",
    "Resultado: obtenemos un listado de 154 publicaciones.\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE author.name = \"Joost Engelfriet\"\n",
    "RETURN count(pub)\n",
    "```\n",
    "Resultado: aplicando esta conculta, obtenemos un número total de publicaciones del autor \"Joost Engelfriet\" de 154, lo que coincide con las consultas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Equivalence - Combinatorics, Algebra, Proofs.\n",
      "2. Home Page\n",
      "3. Clique-Width for Four-Vertex Forbidden Subgraphs.\n",
      "4. Context-Free NCE Graph Grammars.\n",
      "5. How to Remove the Look-Ahead of Top-Down Tree Transducers.\n",
      "6. Extended Multi Bottom-Up Tree Transducers.\n",
      "7. Hierarchies of String Languages Generated by Deterministic Tree Transducers.\n",
      "8. Branching Grammars: A Generalization of ET0L Systems.\n",
      "9. The Equivalence Problem for Deterministic MSO Tree Transducers Is Decidable.\n",
      "10. Determinacy and Rewriting of Top-Down and MSO Tree Transformations.\n",
      "11. Two-Way Finite State Transducers with Nested Pebbles.\n",
      "12. Equality Languages, Fixed Point Languages and Representations of Recursively Enumerable Languages\n",
      "13. Concatenation of Graphs.\n",
      "14. Tree Languages Generated be Context-Free Graph Grammars.\n",
      "15. Macro Grammars, Lindenmayer Systems and Other Copying Devices.\n",
      "16. Translation of Simple Program Schemes.\n",
      "17. Automata with Storage on Infinite Words.\n",
      "18. Formal Properties of One-Visit and Multi-Pass Attribute Grammars.\n",
      "19. Passes, Sweeps and Visits.\n",
      "20. Two-Way Finite State Transducers and Monadic Second-Order Logic.\n",
      "21. A Greibach Normal Form for Context-free Graph Grammars.\n",
      "22. Characterization of High Level Tree Transducers.\n",
      "23. Tree Transducers, L Systems and Two-Way Machines (Extended Abstract)\n",
      "24. Iterated Pushdown Automata and Complexity Classes\n",
      "25. XML transformation by tree-walking transducers with invisible pebbles.\n",
      "26. Apex Graph Grammars.\n",
      "27. Graph Grammars Based on Node Rewriting: An Introduction to NLC Graph Grammars.\n",
      "28. The Term Generating Power of Context-Free Hypergraph Grammars.\n",
      "29. A Characterization of Context-Free NCE Graph Languages by Monadic Second-Order Logic on Trees.\n",
      "30. Node Replacement Graph Grammars.\n",
      "31. Context-free Handle-rewriting Hypergraph Grammars.\n",
      "32. Restricting the complexity of regular DNLC languages.\n",
      "33. Characterizing and Deciding MSO-Definability of Macro Tree Transductions.\n",
      "34. Nested Pebbles and Transitive Closure.\n",
      "35. Net-Based Description Of Parallel Object-Based Systems, or POTs and POPs.\n",
      "36. Attribute Grammars: Attribute Evaluation Methods.\n",
      "37. Elementary Net Systems.\n",
      "38. Graph Grammars and Tree Transducers.\n",
      "39. Regular Characterizations of Macro Tree Transducers.\n",
      "40. A Multiset Semantics for the pi-Calculus with Replication.\n",
      "41. Domino Treewith (Extended Abstract).\n",
      "42. Strong Lexicalization of Tree Adjoining Grammars.\n",
      "43. Deciding the NTS Property of Context-Free Grammars.\n",
      "44. Monadic Second Order Logic and Node Relations on Graphs and Trees.\n",
      "45. Tree-Walking Pebble Automata.\n",
      "46. The Delta Operation: From Strings to Trees to Strings.\n",
      "47. Simple Program Schemes and Formal Languages\n",
      "48. Graph Structure and Monadic Second-Order Logic - A Language-Theoretic Approach.\n",
      "49. Macro Tree Translations of Linear Size Increase are MSO Definable.\n",
      "50. The complexity of Languages Generated by Attribute Grammars.\n",
      "51. Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure.\n",
      "52. Trips on Trees.\n",
      "53. A Multiset Semantics for the pi-Calculus with Replication.\n",
      "54. Iterating Iterated Substitution.\n",
      "55. Multisets and Structural Congruence of the pi-Calculus with Replication.\n",
      "56. Nonterminal Bounded NLC Graph Grammars.\n",
      "57. Structural inclusion in the pi-calculus with replication.\n",
      "58. Surface Tree Languages and Parallel Derivation Trees.\n",
      "59. Look-ahead removal for total deterministic top-down tree transducers.\n",
      "60. Pushdown Machines for the Macro Tree Transducer.\n",
      "61. Determinacy - (Observation Equivalence = Trace Equivalence).\n",
      "62. A Regular Characterization of Graph Languages Definable in Monadic Second-Order Logic.\n",
      "63. X-Automata on omega-Words.\n",
      "64. Characterization and Complexity of Uniformly Non Primitive Labeled 2-Structures.\n",
      "65. As Time Goes By II: More Automatic Complexity Analysis of Concurrent Rule Programs.\n",
      "66. Nonterminal Separation in Graph Grammars.\n",
      "67. Modular Tree Transducers.\n",
      "68. Grammatical Codes of Trees and Terminally Coded Grammars.\n",
      "69. Finitary Compositions of Two-way Finite-State Transductions.\n",
      "70. Bottom-Up and Top-Down Tree Series Transformations.\n",
      "71. MSO definable string transductions and two-way finite-state transducers.\n",
      "72. Complexity of boundary graph languages.\n",
      "73. Automata with Nested Pebbles Capture First-Order Logic with Transitive Closure\n",
      "74. MSO definable string transductions and two-way finite state transducers\n",
      "75. Tree Automata and Tree Grammars.\n",
      "76. The Equivalence Problem for Deterministic MSO Tree Transducers is Decidable\n",
      "77. Look-Ahead Removal for Top-Down Tree Transducers.\n",
      "78. Context-Free Grammars with Storage.\n",
      "79. Reverse Twin Shuffles.\n",
      "80. Book: Graph Structure and Monadic Second-Order Logic. A Language-Theoretic Approach.\n",
      "81. The non-computability of computability.\n",
      "82. The String Generating Power of Context-Free Hypergraph Grammars.\n",
      "83. The Complexity of Regular DNLC Graph Languages.\n",
      "84. Finite Languages for the Representation of Finite Graphs.\n",
      "85. Output String Languages of Compositions of Deterministic Macro Tree Transducers.\n",
      "86. The Translation Power of Top-Down Tree-to-Graph Transducers.\n",
      "87. Extended Macro Grammars and Stack Controlled Machines.\n",
      "88. Simple Multi-Visit Attribute Grammars.\n",
      "89. A Comparison of Tree Transductions Defined by Monadic Second Order Logic and by Attribute Grammars.\n",
      "90. Branching synchronization grammars with nested tables.\n",
      "91. Context Free Normal Systems and ETOL Systems.\n",
      "92. Hierarchies of Hyper-AFLs.\n",
      "93. Regular Description of Context-Free Graph Languages.\n",
      "94. The Copying Power of One-State Tree Transducers.\n",
      "95. Determinacy and rewriting of functional top-down and MSO tree transformations.\n",
      "96. IO and OI. I.\n",
      "97. Logical Description of Contex-Free Graph Languages.\n",
      "98. Hypergraph Languages of Bounded Degree.\n",
      "99. IO and OI. II.\n",
      "100. Boundary Graph Grammars with Dynamic Edge Relabeling.\n",
      "101. Macro Tree Transducers.\n",
      "102. Handle-Rewriting Hypergraph Grammars.\n",
      "103. Deciding equivalence of top-down XML transformations in polynomial time.\n",
      "104. The Equivalence of Bottom-Up and Top-Down Tree-to-Graph Transducers.\n",
      "105. Tree Transducers, L Systems, and Two-Way Machines.\n",
      "106. Top-down Tree Transducers with Regular Look-ahead.\n",
      "107. Bottom-up and Top-down Tree Transformations - A Comparison.\n",
      "108. A Logical Characterization of the Sets of Hypergraphs Defined by Hyperedge Replacement Grammars.\n",
      "109. Erratum to: Top-down Tree Transducers with Regular Look-ahead.\n",
      "110. Clique-Width for 4-Vertex Forbidden Subgraphs.\n",
      "111. Composition Closure of Linear Extended Top-down Tree Transducers.\n",
      "112. Three Hierarchies of Transducers.\n",
      "113. Passes, sweeps, and visits in attribute grammars.\n",
      "114. Fixed Point Languages, Equality Languages, and Representation of Recursively Enumerable Languages.\n",
      "115. Stack Machines and Classes of Nonnested Macro Languages.\n",
      "116. Derivation Trees of Ground Term Rewriting Systems.\n",
      "117. A Comparison of Boundary Graph Grammars and Context-Free Hypergraph Grammars\n",
      "118. Bounded Nesting in Macro Grammars\n",
      "119. Passes and Paths of Attributive Grammars\n",
      "120. Decidability of the Finiteness of Ranges of Tree Transductions.\n",
      "121. The generative power of delegation networks.\n",
      "122. Iterated Stack Automata and Complexity Classes\n",
      "123. Look-Ahead on Pushdowns\n",
      "124. Macro Tree Transducers, Attribute Grammars, and MSO Definable Tree Translations.\n",
      "125. Linear Graph Grammars: Power and Complexity\n",
      "126. Equality Languages and Fixed Point Languages\n",
      "127. The Power to Two-Way Deterministic Checking Stack Automata\n",
      "128. A Tranlsational Theorem for the Class of EOL Languages\n",
      "129. Domino Treewidth.\n",
      "130. The complexity of the circularity problem for attribute grammars: a note on a counterexample for a simpler construction.\n",
      "131. Prefix and Equality Languages of Rational Functions are Co-Context-Free.\n",
      "132. A Note on Infinite Trees.\n",
      "133. An exercise in structural congruence.\n",
      "134. Copying Theorems.\n",
      "135. On Tree Transducers for Partial Functions.\n",
      "136. A Kleene characterization of computability.\n",
      "137. An Elementary Proof of Double Greibach Normal Form.\n",
      "138. The equivalence problem for deterministic MSO tree transducers is decidable.\n",
      "139. Iterated Deterministic Substitution.\n",
      "140. Attribute Storage Optimization by Stacks.\n",
      "141. A comparison of pebble tree transducers with macro tree transducers.\n",
      "142. Two-way pebble transducers for partial functions and their composition.\n",
      "143. Context-Free Hypergraph Grammars have the Same Term-Generating Power as Attribute Grammars.\n",
      "144. The Formal Power of One-Visit Attribute Grammars.\n",
      "145. Extended Linear Macro Grammars, Iteration Grammars, and Register Programs.\n",
      "146. Branching Processes of Petri Nets.\n",
      "147. The time complexity of typechecking tree-walking tree transducers.\n",
      "148. Apex Graph Grammars and Attribute Grammars.\n",
      "149. Axioms for Generalized Graphs, Illustrated by a Cantor-Bernstein Proposition.\n",
      "150. A new natural structural congruence in the pi-calculus with replication.\n",
      "151. Context-Free Graph Grammars and Concatenation of Graphs.\n",
      "152. Extended multi bottom-up tree transducers.\n",
      "153. High Level Tree Transducers and Iterated Pushdown Tree Transducers.\n",
      "154. Context-Free Graph Languages of Bounded Degree are Generated by Apex Graph Grammars.\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (author)-[:HAS_PUBLISHED]->(pub)'\n",
    "                  'WHERE author.name = \"Joost Engelfriet\"'\n",
    "                  'RETURN pub.title')\n",
    "for i, title in enumerate(data) :\n",
    "    print ('%d. %s' %(i+1, title[u'pub.title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 publicaciones\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (author)-[:HAS_PUBLISHED]->(pub)'\n",
    "                  'WHERE author.name = \"Joost Engelfriet\"'\n",
    "                  'RETURN count(pub)')\n",
    "print ('%d publicaciones' \n",
    "       %(data[0][\"count(pub)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 4: Autores con los que ha colaborado el autor \"Sven Skyum\".\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE author.name = \"Sven Skyum\"\n",
    "MATCH (authors)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE NOT(authors.name CONTAINS \"Sven Skyum\")\n",
    "RETURN DISTINCT authors.name\n",
    "\n",
    "```\n",
    "Resultado: los colaboradores del autor \"Sven Skyum\" son 21: Navid Talebanfard, Jayalal Sarma, Balagopal Komarath, Kristoffer Arnsfelt Hansen, Leslie G. Valiant, Peter Bro Miltersen, Gudmund Skovbjerg Frandsen, Neil D. Jones, Chi-Jen Lu, David A. Mix Barrington, Mogens Nielsen, Erik Meineche Schmidt, Charles Rackoff, S. Berkowitz, Grzegorz Rozenberg, Andrzej Ehrenfeucht, Peter G. Binderup, Joost Engelfriet, Hanne Riis Nielson, Mark Jerrum y Arto Salomaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Navid Talebanfard\n",
      "2. Jayalal Sarma\n",
      "3. Balagopal Komarath\n",
      "4. Kristoffer Arnsfelt Hansen\n",
      "5. Leslie G. Valiant\n",
      "6. Peter Bro Miltersen\n",
      "7. Gudmund Skovbjerg Frandsen\n",
      "8. Neil D. Jones\n",
      "9. Chi-Jen Lu\n",
      "10. David A. Mix Barrington\n",
      "11. Mogens Nielsen\n",
      "12. Erik Meineche Schmidt\n",
      "13. Charles Rackoff\n",
      "14. S. Berkowitz\n",
      "15. Grzegorz Rozenberg\n",
      "16. Andrzej Ehrenfeucht\n",
      "17. Peter G. Binderup\n",
      "18. Joost Engelfriet\n",
      "19. Hanne Riis Nielson\n",
      "20. Mark Jerrum\n",
      "21. Arto Salomaa\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (author)-[:HAS_PUBLISHED]->(pub)'\n",
    "                  'WHERE author.name = \"Sven Skyum\" '\n",
    "                  'MATCH (authors)-[:HAS_PUBLISHED]->(pub) '\n",
    "                  'WHERE NOT(authors.name CONTAINS \"Sven Skyum\") '\n",
    "                  'RETURN DISTINCT authors.name')\n",
    "for i, author in enumerate(data) :\n",
    "    print ('%d. %s' %(i+1, author[u'authors.name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 5: Autores de una publicación titulada: \"The RIKEN integrated database of mammals\".\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE pub.title = \"The RIKEN integrated database of mammals.\"\n",
    "RETURN author.name\n",
    "```\n",
    "Resultado: los autores de la publicación titulada \"The RIKEN integrated database of mammals\" son 28: Shigeharu Wakana, Hideya Kawaji, Atsushi Yoshiki, Yukio Nakamura, Takehide Murata, Kaoru Fukami-Kobayashi, Nobuhiko Tanaka, Osamu Ohara, S. Sujatha Mohan, Terue Takatsuki, Koji Doi, Yoshihide Hayashizaki, Kazunori Waki, Riichiro Mizoguchi, Akihiro Matsushima, Yoshiki Mochizuki, Manabu Ishii, Yuko Yoshida, Yuichi Obata, Atsushi Hijikata, Koro Nishikata, Norio Kobayashi, Tetsuro Toyoda, Satoshi Takahashi, Teiichi Furuichi, Yuko Makita, Kouji Kozaki y Hiroshi Masuya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tetsuro Toyoda\n",
      "2. Yuichi Obata\n",
      "3. Riichiro Mizoguchi\n",
      "4. Yoshihide Hayashizaki\n",
      "5. Osamu Ohara\n",
      "6. S. Sujatha Mohan\n",
      "7. Kaoru Fukami-Kobayashi\n",
      "8. Takehide Murata\n",
      "9. Atsushi Yoshiki\n",
      "10. Yukio Nakamura\n",
      "11. Shigeharu Wakana\n",
      "12. Hideya Kawaji\n",
      "13. Teiichi Furuichi\n",
      "14. Kouji Kozaki\n",
      "15. Atsushi Hijikata\n",
      "16. Satoshi Takahashi\n",
      "17. Akihiro Matsushima\n",
      "18. Manabu Ishii\n",
      "19. Nobuhiko Tanaka\n",
      "20. Kazunori Waki\n",
      "21. Terue Takatsuki\n",
      "22. Koji Doi\n",
      "23. Yoshiki Mochizuki\n",
      "24. Yuko Yoshida\n",
      "25. Koro Nishikata\n",
      "26. Norio Kobayashi\n",
      "27. Yuko Makita\n",
      "28. Hiroshi Masuya\n"
     ]
    }
   ],
   "source": [
    "data = \\\n",
    "graph.data('MATCH (author)-[:HAS_PUBLISHED]->(pub) '\n",
    "           'WHERE pub.title = \"The RIKEN integrated database of mammals.\" '\n",
    "           'RETURN author.name')\n",
    "\n",
    "for i, author in enumerate(data) :\n",
    "    print ('%d. %s' %(i+1, author[u'author.name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 6: Publicaciones realizadas en 1995 (sin repetir)\n",
    "\n",
    "```\n",
    "MATCH (pub:Publication)\n",
    "WHERE pub.year = \"1995\"\n",
    "return count(DISTINCT pub)\n",
    "```\n",
    "Resultado: 1908171 publicaciones en 1995."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908171 publicaciones distintas\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (pub:Publication)'\n",
    "                  'WHERE pub.year = \"1995\"'\n",
    "                  'return count(DISTINCT pub)')\n",
    "print ('%d publicaciones distintas' \n",
    "       %(data[0][\"count(DISTINCT pub)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 7: Número de autores que publicaron en 2001\n",
    "\n",
    "```\n",
    "MATCH (authors)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE pub.year=\"2001\"\n",
    "RETURN count(DISTINCT authors)\n",
    "```\n",
    "Resultado: 108704 autores diferentes publicaron en 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108704 publicaciones distintas\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (authors)-[:HAS_PUBLISHED]->(pub)'\n",
    "                  'WHERE pub.year=\"2001\"'\n",
    "                  'RETURN count(DISTINCT authors)')\n",
    "print ('%d publicaciones distintas' \n",
    "       %(data[0][\"count(DISTINCT authors)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 8: Número de documentos tipo `inproceedings`.\n",
    "\n",
    "```\n",
    "MATCH (pub:Publication)\n",
    "WHERE pub.type=\"inproceedings\"\n",
    "RETURN count(DISTINCT pub)\n",
    "```\n",
    "Resultado: 1946370 de documentos tipo `inproceedings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946370 publicaciones distintas\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (pub:Publication)'\n",
    "                  'WHERE pub.type=\"inproceedings\"'\n",
    "                  'RETURN count(DISTINCT pub)')\n",
    "print ('%d publicaciones distintas' \n",
    "       %(data[0][\"count(DISTINCT pub)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 9: Número de autores que han escrito documentos de tipo `article`.\n",
    "\n",
    "```\n",
    "MATCH (authors)-[:HAS_PUBLISHED]->(pub)\n",
    "WHERE pub.type=\"article\"\n",
    "RETURN count(DISTINCT authors)\n",
    "```\n",
    "Resultado: 1.161.886 autores han escrito artículos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161886 publicaciones distintas\n"
     ]
    }
   ],
   "source": [
    "data = graph.data('MATCH (authors)-[:HAS_PUBLISHED]->(pub)'\n",
    "                  'WHERE pub.type=\"article\"'\n",
    "                  'RETURN count(DISTINCT authors)')\n",
    "print ('%d publicaciones distintas' \n",
    "       %(data[0][\"count(DISTINCT authors)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 10: Publicación con más autores\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "RETURN pub, COLLECT(author) as authors\n",
    "ORDER BY SIZE(authors) DESC LIMIT 1\n",
    "```\n",
    "\n",
    "Resultado: en subgrafos de menor tamaño, hemos obtenido un grafo, con un nodo central tipo publicación `inprocedings` conectado con tantos nodos de tipo `Author` como autores tiene. Sin embargo, se trata de una consulta tremendamente pesada, que no llega a proporcionar ningún resultado con la base de datos completa (`There is not enough memory to perform the current task`).\n",
    "\n",
    "Para una base de datos reducida, de 20000 nodos, utilizada para hacer pruebas, sí hemos obtenido resultados. Se trata de un grafo, cuyo nodo central de tipo publicación `inprocedings`, se titula *Massively distributed authorship of academic papers* y está conectado con 30 autores diferentes:\n",
    "<img src=\"consulta_10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consulta 11: Autor con más publicaciones\n",
    "\n",
    "```\n",
    "MATCH (author)-[:HAS_PUBLISHED]->(pub)\n",
    "RETURN author, COLLECT(pub) as publications\n",
    "ORDER BY SIZE(publications) DESC LIMIT 1\n",
    "```\n",
    "\n",
    "Resultado: los mismos problemas que en el caso anterior. Mostramos también, de forma ilustrativa, el resultado para la misma base de datos reducida (el nodo central es el autor *Bin Wang*, autor de 6 publicaciones.):\n",
    "<img src=\"consulta_11.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entregables\n",
    "La presente práctica consta de los siguientes entregables:\n",
    "1. `Práctica BasesdeDatosNoConvencionales - Arias, Monjas, Sánchez.pdf`. El presente documento, conversión a PDF de un *notebook* en Python.\n",
    "\n",
    "El código de la práctica puede encontrarse en GitHub. Es posible clonarlo con la siguiente URL: <https://github.com/raul-sanchez-martin/practica_mongo.git>:\n",
    "1. `PrácticaBasesdeDatosNoSQL.ipynb`. El *notebook* en el que hemos desarrollado el trabajo.\n",
    "2. `splitter.py`. El *script* de Python con el que hemos partido el fichero XML de entrada en ficheros más manejables.\n",
    "3. `parser.py`. El *script* de Python con el que se han *parseado* los ficheros XML para transformarlos en ficheros JSON (Line-JSON, de hecho) para su carga en MongoDB.\n",
    "4. `load_documents.sh`. Un *script* en `bash` con el que se cargan en MongoDB los contenidos de los ficheros JSON generados por el *script* citado en el punto anterior.\n",
    "5. `export_db`. Un *script* en Python con el que generamos los ficheros CSV necesarios para ejecutar la carga en Neo4J.\n",
    "\n",
    "En el mismo repositorio podemos encontrar también todas las imágenes incluidas en la memoria (en el directorio `resultados_consultas`).\n",
    "\n",
    "Finalmente, todos los ficheros de carga están disponibles en AWS S3. Las direcciones se han detallado en la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:datascience27]",
   "language": "python",
   "name": "conda-env-datascience27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
